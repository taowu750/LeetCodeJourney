# 1. 动态规划定义<sup id="a1">[\[1\]](#f1)</sup>

首先，**动态规划问题的一般形式就是求最值**。动态规划其实是运筹学的一种最优化方法，只不过在计算机问题上应用比较多，
比如说让你求最长递增子序列呀，最小编辑距离呀等等。

既然是要求最值，核心问题是什么呢？**求解动态规划的核心问题是穷举**。因为要求最值，肯定要把所有可行的答案穷举出来，
然后在其中找最值呗。

动态规划的求解有以下几个特点：
1. 动态规划的穷举有点特别，因为这类问题存在**重叠子问题**，如果暴力穷举的话效率会极其低下，所以需要**备忘录**
或者**DP table**来优化穷举过程，避免不必要的计算。
2. 而且，动态规划问题一定会具备**最优子结构**，才能通过子问题的最值得到原问题的最值。
要符合「最优子结构」，**子问题间必须互相独立**。
3. 另外，虽然动态规划的核心思想就是穷举求最值，但是问题可以千变万化，穷举所有可行解其实并不是一件容易的事，
只有列出正确的**状态转移方程**才能正确地穷举。

以上提到的就是**动态规划三要素：重叠子问题、最优子结构、状态转移方程**。在实际的算法问题中，**写出状态转移方程是最困难的**。
下面是一个思维框架，辅助你思考状态转移方程：

**明确 base case -> 明确「状态」-> 明确「选择」 -> 定义 dp 数组/函数的含义**。按上面的套路走，最后的结果就可以套这个框架：
```python
# 初始化 base case
dp[0][0][...] = base
# 进行状态转移
for 状态1 in 状态1的所有取值：
    for 状态2 in 状态2的所有取值：
        for ...
            dp[状态1][状态2][...] = 求最值(选择1，选择2...)
```

# 2. 两个例子

## 2.1 斐波那契数列

请读者不要嫌弃这个例子简单，只有简单的例子才能让你把精力充分集中在算法背后的通用思想和技巧上，
而不会被那些隐晦的细节问题搞的莫名其妙。

### 2.1.1 暴力递归解法

斐波那契数列的数学形式就是递归的，写成代码就是这样：
```java
int fib(int N) {
    if (N == 1 || N == 2) return 1;
    return fib(N - 1) + fib(N - 2);
}
```

这个不用多说了，学校老师讲递归的时候似乎都是拿这个举例。我们也知道这样写代码虽然简洁易懂，但是十分低效，低效在哪里？
假设 `n = 20`，请画出递归树：

![斐波那契数列][fib]

想要计算原问题 f(20)，我就得先计算出子问题 f(19) 和 f(18)，然后要计算 f(19)，我就要先算出子问题 f(18) 和 f(17)，以此类推。
最后遇到 f(1) 或者 f(2) 的时候，结果已知，就能直接返回结果，递归树不再向下生长了。

**递归算法的时间复杂度怎么计算？就是用子问题个数乘以解决一个子问题需要的时间**。
1. 首先计算子问题个数，即递归树中节点的总数。显然二叉树节点总数为指数级别，所以子问题个数为 O(2^n)。
2. 然后计算解决一个子问题的时间，在本算法中，没有循环，只有 f(n - 1) + f(n - 2) 一个加法操作，时间为 O(1)。
3. 所以，这个算法的时间复杂度为二者相乘，即 O(2^n)，指数级别，爆炸。

观察递归树，很明显发现了算法低效的原因：存在大量重复计算，比如 f(18) 被计算了两次，而且你可以看到，以 f(18) 为根的这个递归树体量巨大，
多算一遍，会耗费巨大的时间。更何况，还不止 f(18) 这一个节点被重复计算，所以这个算法及其低效。

这就是动态规划问题的第一个性质：**重叠子问题**。下面，我们想办法解决这个问题。

### 2.1.2 带备忘录的递归解法

明确了问题，其实就已经把问题解决了一半。即然耗时的原因是重复计算，那么我们可以造一个**备忘录**，
每次算出某个子问题的答案后别急着返回，先记到「备忘录」里再返回；每次遇到一个子问题先去「备忘录」里查一查，
如果发现之前已经解决过这个问题了，直接把答案拿出来用，不要再耗时去计算了。

一般使用一个数组充当这个「备忘录」，当然你也可以使用哈希表（字典），思想都是一样的：
```java
int fib(int N) {
    if (N < 1) 
        return 0;

    // 备忘录全初始化为 0
    int[] memo[N + 1];

    // 进行带备忘录的递归
    return helper(memo, N);
}

int helper(int[] memo, int n) {
    // base case
    if (n == 1 || n == 2) 
        return 1;

    // 已经计算过
    if (memo[n] != 0) 
        return memo[n];

    memo[n] = helper(memo, n - 1) + helper(memo, n - 2);

    return memo[n];
}
```

现在，画出递归树，你就知道「备忘录」到底做了什么：

![使用备忘录后的斐波那契数列][fib-reduce]

实际上，带「备忘录」的递归算法，把一棵存在巨量冗余的递归树通过**剪枝**，改造成了一幅**不存在冗余的递归图**，
极大减少了子问题（即递归图中节点）的个数：

![斐波那契数列递归图][fib-graph]

**递归算法的时间复杂度怎么计算？就是用子问题个数乘以解决一个子问题需要的时间**：
1. 子问题个数，即图中节点的总数，由于本算法不存在冗余计算，子问题就是 f(1), f(2), f(3) ... f(20)，
数量和输入规模 n = 20 成正比，所以子问题个数为 O(n)。
2. 解决一个子问题的时间，同上，没有什么循环，时间为 O(1)。
3. 所以，本算法的时间复杂度是 O(n)。比起暴力算法，是降维打击。

至此，带备忘录的递归解法的效率已经和迭代的动态规划解法一样了。实际上，这种解法和迭代的动态规划已经差不多了，
只不过这种方法叫做**自顶向下**，动态规划叫做**自底向上**。
 - 啥叫「自顶向下」？注意我们刚才画的递归树（或者说图），是从上向下延伸，都是从一个规模较大的原问题比如说 f(20)，
 向下逐渐分解规模，直到 f(1) 和 f(2) 这两个 base case，然后逐层返回答案，这就叫「自顶向下」。
 - 啥叫「自底向上」？反过来，我们直接从最底下，最简单，问题规模最小的 f(1) 和 f(2) 开始往上推，直到推到我们想要的答案 f(20)，
 这就是动态规划的思路，这也是为什么动态规划一般都脱离了递归，而是由循环迭代完成计算。

### 2.1.3 dp 数组的迭代解法

有了上一步「备忘录」的启发，我们可以把这个「备忘录」独立出来成为一张表，就叫做 **DP table** 吧，
在这张表上完成「自底向上」的推算岂不美哉！
```java
int fib(int N) {
    if (N < 1) 
        return 0;
    if (N == 1 || N == 2) 
        return 1;

    int[] dp[N + 1];
    // base case
    dp[1] = dp[2] = 1;
    for (int i = 3; i <= N; i++)
        dp[i] = dp[i - 1] + dp[i - 2];
    return dp[N];
}
```

下面是解释图，而且你发现这个 DP table 特别像之前那个「剪枝」后的结果，只是反过来算而已。实际上，
带备忘录的递归解法中的「备忘录」，最终完成后就是这个 DP table，所以说这两种解法其实是差不多的，
大部分情况下，效率也基本相同。

![DP table][fib-table]

### 2.1.4 状态方程

这里，引出「状态转移方程」这个名词，实际上就是描述问题结构的数学形式：

![斐波那契数列状态方程][fib-function]

为啥叫「状态转移方程」？其实就是为了听起来高端。你把 f(n) 想做一个状态 n，这个状态 n 是由状态 n - 1 和状态 n - 2 相加转移而来，
这就叫**状态转移**，仅此而已。

你会发现，上面的几种解法中的所有操作，例如 `return f(n - 1) + f(n - 2)，dp[i] = dp[i - 1] + dp[i - 2]`，
以及对备忘录或 DP table 的初始化操作，都是围绕这个方程式的不同表现形式。**可见列出状态转移方程的重要性，它是解决问题的核心**。
而且很容易发现，其实状态转移方程直接代表着暴力解法。

千万不要看不起暴力解，动态规划问题最困难的就是写出这个暴力解，即状态转移方程。只要写出暴力解，
优化方法无非是用备忘录或者 DP table，再无奥妙可言。

### 2.1.5 状态压缩

这个例子的最后，讲一个细节优化。细心的读者会发现，**根据斐波那契数列的状态转移方程，当前状态只和之前的两个状态有关**，
其实并不需要那么长的一个 DP table 来存储所有的状态，只要想办法存储之前的两个状态就行了。所以，可以进一步优化，
把空间复杂度降为 O(1)：
```java
int fib(int n) {
    if (n < 1) return 0;
    if (n == 2 || n == 1) 
        return 1;
    int prev = 1, curr = 1;
    for (int i = 3; i <= n; i++) {
        int sum = prev + curr;
        prev = curr;
        curr = sum;
    }
    return curr;
}
```

这个技巧就是所谓的**状态压缩**，如果我们发现每次状态转移只需要 DP table 中的一部分，
那么可以尝试用状态压缩来缩小 DP table 的大小，只记录必要的数据，上述例子就相当于把DP table 的大小从 n 缩小到 2。
后续的动态规划章节中我们还会看到这样的例子，一般来说是把一个二维的 DP table 压缩成一维，
即把空间复杂度从 O(n^2) 压缩到 O(n)。

有人会问，动态规划的另一个重要特性「最优子结构」，怎么没有涉及？下面会涉及。斐波那契数列的例子严格来说不算动态规划，
因为没有涉及求最值，以上旨在说明重叠子问题的消除方法，演示得到最优解法逐步求精的过程。下面，看第二个例子，凑零钱问题。

## 2.2 凑零钱问题

先看下题目：给你 `k` 种面值的硬币，面值分别为 `c1, c2 ... ck`，每种硬币的数量无限，再给一个总金额 `amount`，
问你最少需要几枚硬币凑出这个金额，如果不可能凑出，算法返回 -1 。算法的函数签名如下：
```java
// coins 中是可选硬币面值，amount 是目标金额
int coinChange(int[] coins, int amount);
```

比如说 `k = 3`，面值分别为 1，2，5，总金额 `amount = 11`。那么最少需要 3 枚硬币凑出，即 11 = 5 + 5 + 1。

你认为计算机应该如何解决这个问题？显然，就是把所有可能的凑硬币方法都穷举出来，然后找找看最少需要多少枚硬币。

### 2.2.1 暴力递归解法

首先，这个问题是动态规划问题，因为它具有**最优子结构**的。要符合「最优子结构」，子问题间必须互相独立。
啥叫相互独立？你肯定不想看数学证明，我用一个直观的例子来讲解。

比如说，假设你考试，每门科目的成绩都是互相独立的。你的原问题是考出最高的总成绩，那么你的子问题就是要把语文考到最高，
数学考到最高…… 为了每门课考到最高，你要把每门课相应的选择题分数拿到最高，填空题分数拿到最高…… 当然，最终就是你每门课都是满分，
这就是最高的总成绩。

得到了正确的结果：最高的总成绩就是总分。因为这个过程符合最优子结构，“每门科目考到最高”这些子问题是互相独立，互不干扰的。

但是，如果加一个条件：你的语文成绩和数学成绩会互相制约，数学分数高，语文分数就会降低，反之亦然。这样的话，
显然你能考到的最高总成绩就达不到总分了，按刚才那个思路就会得到错误的结果。因为子问题并不独立，语文数学成绩无法同时最优，
所以最优子结构被破坏。

回到凑零钱问题，为什么说它符合最优子结构呢？比如你想求 `amount = 11` 时的最少硬币数（原问题），
如果你知道凑出 `amount = 10` 的最少硬币数（子问题），你只需要把子问题的答案加一（再选一枚面值为 1 的硬币）就是原问题的答案。
因为硬币的数量是没有限制的，所以子问题之间没有相互制，是互相独立的。

那么，既然知道了这是个动态规划问题，就要思考如何列出正确的状态转移方程：
1. **明确「base case」**。这个很简单，显然目标金额 `amount` 为 0 时算法返回 0，因为不需要任何硬币就已经凑出目标金额了。
2. **明确「状态」，也就是原问题和子问题中会变化的变量**。我们需要知道什么信息，才能将原问题分解为规模更小的子问题？
由于硬币数量无限，硬币的面额也是题目给定的，只有目标金额会不断地向 base case 靠近，所以唯一的「状态」就是目标金额 `amount`。
3. **明确「选择」，也就是导致「状态」产生变化的行为**。目标金额为什么变化呢，因为你在选择硬币，你每选择一枚硬币，
就相当于减少了目标金额。所以说所有硬币的面值，就是你的「选择」。
4. **明确 dp 函数/数组的定义**。我们这里讲的是自顶向下的解法，所以会有一个递归的 dp 函数，
一般来说函数的参数就是状态转移中会变化的量，也就是上面说到的「状态」；函数的返回值就是题目要求我们计算的量。
就本题来说，状态只有一个，即「目标金额」，题目要求我们计算凑出目标金额所需的最少硬币数量。**对于 dp 数组，还要明确初始值，
以及从上一次中继承什么状态**。所以我们可以这样定义 dp 函数：
    > `dp(n)` 的定义：输入一个目标金额 `n`，返回凑出目标金额 `n` 的最少硬币数量。

搞清楚上面这几个关键点，解法的伪码就可以写出来了：
```java
// 伪码框架
int coinChange(int[] coins, int amount) {
    // 题目要求的最终结果是 dp(amount)
    return dp(int[] coins, amount)
}

// 定义：要凑出金额 n，至少要 dp(n) 个硬币
int dp(int[] coins, int amount) {
    // 做选择，选择需要硬币最少的那个结果
    for (int coin: coins)
        res = min(res, 1 + dp(n - coin));
    return res
}
```

根据伪码，我们加上 base case 即可得到最终的答案。显然目标金额为 0 时，所需硬币数量为 0；当目标金额小于 0 时，无解，返回 -1：
```java
public int coinChange(int[] coins, int amount) {
    return dp(coins, amount);
}

private int dp(int[] coins, int amount) {
    // 基准条件
    if (amount == 0)
        return 0;
    if (amount < 0)
        return -1;

    // 自顶向下求解
    int res = Integer.MAX_VALUE;
    for (int coin : coins) {
        int subSolution = dp(coins, amount - coin, memory);
        // 跳过没有解的子问题
        if (subSolution == -1)
            continue;
        // 不要忘了加 1
        res = Math.min(res, 1 + subSolution);
    }
    
    // 所有子问题都无解，则最终无解
    return res != Integer.MAX_VALUE ? res : -1;
}
```

至此，状态转移方程其实已经完成了，以上算法已经是暴力解法了，以上代码的数学形式就是状态转移方程：

![凑零钱自顶向下 dp][coin-function]

至此，这个问题其实就解决了，只不过需要消除一下重叠子问题，比如 `amount = 11, coins = {1,2,5}` 时画出递归树看看：

![凑零钱递归树][coin-tree]

递归算法的时间复杂度分析：子问题总数 x 每个子问题的时间。
子问题总数为递归树节点个数，这个比较难看出来，是 O(n^k)，总之是指数级别的。每个子问题中含有一个 for 循环，复杂度为 O(k)。
所以总时间复杂度为 O(k * n^k)，指数级别。

### 2.2.2 带备忘录的递归解法

类似之前斐波那契数列的例子，只需要稍加修改，就可以通过备忘录消除子问题：
```java
public int coinChange(int[] coins, int amount) {
    // 状态是金额，结果是凑成这个金额所需的最少硬币数。
    // 因为不管选择哪个硬币，造成的结果类型都是相同的，所以选用一维数组。
    int[] memory = new int[amount + 1];
    // 因为凑成 amount 金额的硬币数最多只可能等于 amount（全用 1 元面值的硬币），
    // 所以初始化为 amount + 1 就相当于初始化为正无穷，便于后续取最小值。
    Arrays.fill(memory, amount + 1);
    return dp(coins, amount, memory);
}

private int dp(int[] coins, int amount, int[] memory) {
    // 基准条件
    if (amount == 0)
        return 0;
    if (amount < 0)
        return -1;

    // 保存的子问题
    int exist = memory[amount];
    if (exist != memory.length)
        return exist;

    // 自顶向下求解
    int res = memory.length;
    for (int coin : coins) {
        int subSolution = dp(coins, amount - coin, memory);
        // 跳过没有解的子问题
        if (subSolution == -1)
            continue;
        // 不要忘了加 1
        res = Math.min(res, 1 + subSolution);
    }
    // 所有子问题都无解，则最终无解
    res = res != memory.length ? res : -1;
    // 保存子问题的解
    memory[amount] = res;

    return res;
}
```

不画图了，很显然「备忘录」大大减小了子问题数目，完全消除了子问题的冗余，所以子问题总数不会超过金额数 n，即子问题数目为 O(n)。
处理一个子问题的时间不变，仍是 O(k)，所以总的时间复杂度是 O(kn)。

### 2.2.3 dp 数组的迭代解法

当然，我们也可以自底向上使用 dp table 来消除重叠子问题，关于「状态」「选择」和 base case 与之前没有区别，
`dp` 数组的定义和刚才 `dp` 函数类似，也是把「状态」，也就是目标金额作为变量。不过 `dp` 函数体现在函数参数，
而 `dp` 数组体现在数组索引：
> `dp` 数组的定义：当目标金额为 `i` 时，至少需要 `dp[i]` 枚硬币凑出。

根据我们文章开头给出的动态规划代码框架可以写出如下解法：
```java
public int coinChange(int[] coins, int amount) {
    if (amount == 0)
        return 0;
    // dp table 大小为 amount + 1，初始值为 amount + 1
    int[] dp = new int[amount + 1];
    Arrays.fill(dp, amount + 1);
    // base case
    dp[0] = 0;
    // 外层 for 循环在遍历所有状态的所有取值
    for (int status = 0; status < dp.length; status++) {
        // 内层 for 循环在求所有选择的最小值
        for (int coin : coins) {
            // 子问题无解，跳过
            if (status - coin < 0)
                continue;
            dp[status] = Math.min(dp[status], 1 + dp[status - coin]);
        }
    }

    return dp[amount] == amount + 1 ? -1 : dp[amount];
}
```

# 3. 最优子结构详解

## 3.1 定义

「最优子结构」是某些问题的一种特定性质，并不是动态规划问题专有的。也就是说，很多问题其实都具有最优子结构，只是其中大部分不具有重叠子问题，
所以我们不把它们归为动态规划系列问题而已。

我先举个很容易理解的例子：假设你们学校有 10 个班，你已经计算出了每个班的最高考试成绩。那么现在我要求你计算全校最高的成绩，你会不会算？
当然会，而且你不用重新遍历全校学生的分数进行比较，而是只要在这 10 个最高成绩中取最大的就是全校的最高成绩。

我给你提出的这个问题就符合最优子结构：可以从子问题的最优结果推出更大规模问题的最优结果。让你算每个班的最优成绩就是子问题，
你知道所有子问题的答案后，就可以借此推出全校学生的最优成绩这个规模更大的问题的答案。

你看，这么简单的问题都有最优子结构性质，只是因为显然没有重叠子问题，所以我们简单地求最值肯定用不出动态规划。

## 3.2 改造问题

再举个例子：假设你们学校有 10 个班，你已知每个班的最大分数差（最高分和最低分的差值）。那么现在我让你计算全校学生中的最大分数差，
你会不会算？可以想办法算，但是肯定不能通过已知的这 10 个班的最大分数差推到出来。
因为这 10 个班的最大分数差不一定就包含全校学生的最大分数差，比如全校的最大分数差可能是 3 班的最高分和 6 班的最低分之差。

那么遇到这种最优子结构失效情况，怎么办？策略是：**改造问题**。对于最大分数差这个问题，我们不是没办法利用已知的每个班的分数差吗，
那我只能这样写一段暴力代码：
```java
int result = 0;
for (Student a : school) {
    for (Student b : school) {
        if (a == b)
            continue;
        result = max(result, |a.score - b.score|);
    }
}
return result;
```

改造问题，也就是把问题等价转化：最大分数差，不就等价于最高分数和最低分数的差么，那不就是要求最高和最低分数么，
不就是我们讨论的第一个问题么，不就具有最优子结构了么？那现在改变思路，借助最优子结构解决最值问题，再回过头解决最大分数差问题，
是不是就高效多了？

当然，上面这个例子太简单了，不过请读者回顾一下，我们做动态规划问题，是不是一直在求各种最值，本质跟我们举的例子没啥区别，
无非需要处理一下重叠子问题。

## 3.3 例 1：4 键键盘

**对 dp 数组的不同定义需要完全不同的逻辑，从而产生完全不同的解法**。

首先看一下题目：

![4键键盘][four-title]

如何在 N 次敲击按钮后得到最多的 A？我们穷举呗，对于每次按键，我们可以穷举四种可能，很明显就是一个动态规划问题。

### 3.3.1 第一种思路

这种思路会很容易理解，但是效率并不高，我们直接走流程：**对于动态规划问题，首先要明白有哪些「状态」，有哪些「选择」**。

具体到这个问题，对于每次敲击按键，有哪些「选择」是很明显的：4 种，就是题目中提到的四个按键，
分别是 A、C-A、C-C、C-V（Ctrl 简写为 C）。

接下来，思考一下对于这个问题有哪些「状态」？或者换句话说，**我们需要知道什么信息，才能将原问题分解为规模更小的子问题？**

你看我这样定义三个状态行不行：第一个状态是剩余的按键次数，用 `n` 表示；第二个状态是当前屏幕上字符 A 的数量，
用 `a_num` 表示；第三个状态是剪切板中字符 A 的数量，用 `copy` 表示。

如此定义「状态」，就可以知道 base case：当剩余次数 `n` 为 0 时，`a_num` 就是我们想要的答案。

结合刚才说的 4 种「选择」，我们可以把这几种选择通过状态转移表示出来：
```
dp(n - 1, a_num + 1, copy),    # A
解释：按下 A 键，屏幕上加一个字符
同时消耗 1 个操作数

dp(n - 1, a_num + copy, copy), # C-V
解释：按下 C-V 粘贴，剪切板中的字符加入屏幕
同时消耗 1 个操作数

dp(n - 2, a_num, a_num)        # C-A C-C
解释：全选和复制必然是联合使用的，
剪切板中 A 的数量变为屏幕上 A 的数量
同时消耗 2 个操作数
```

这样可以看到问题的规模 `n` 在不断减小，肯定可以到达 `n = 0` 的 base case，所以这个思路是正确的：
```java
class Status implements Comparable<Status> {
    
    int n, aNum, copy;

    Status(int n, int aNum, int copy) {
        this.n = n;
        this.aNum = aNum;
        this.copy = copy;
    }

    public int compareTo(Status o) {
        int cmp = Integer.compare(n, o.n);
        return cmp != 0 
                ? cmp 
                : (cmp = Integer.compare(aNum, o.aNum)) != 0 ? cmp : Integer.compare(copy, o.copy);
    }
}

public int firstMethod(int N) {
    return dp(N, 0, 0, new HashMap<>());
}

private int dp(int N, int aNum, int copy, Map<Status, Integer> memory) {
    if (N <= 0)
        return aNum;
    Status s = new Status(N, aNum, copy);
    int max = memory.getOrDefault(s, -1);
    if (max != -1)
        return max;
    max = Math.max(dp(N - 1, aNum + 1, copy, memory),       // A
            Math.max(dp(N - 1, aNum + copy, copy, memory),  // C-A
                    dp(N - 2, aNum, aNum, memory)));        // C-A C-C
    memory.put(s, max);

    return max;
}
```

尝试分析一下这个算法的时间复杂度，就会发现不容易分析。我们可以把这个 `dp` 函数写成 `dp` 数组：
```
dp[n][a_num][copy]
# 状态的总数（时空复杂度）就是这个三维数组的体积
```

我们知道变量 `n` 最多为 `N`，但是 `a_num` 和 `copy` 最多为多少我们很难计算，复杂度起码也有 O(N^3) 吧。
所以这个算法并不好，复杂度太高，且已经无法优化了。

### 3.3.2 第二种思路

这种思路稍微有点复杂，但是效率高。继续走流程，「选择」还是那 4 个，但是这次我们只定义一个「状态」，也就是剩余的敲击次数 `n`。

这个算法基于这样一个事实，最优按键序列一定只有两种情况：
1. 要么一直按 A：A,A,…A（当 `N` 比较小时）。
2. 要么是这么一个形式：A,A,…C-A,C-C,C-V,C-V,…C-V（当 `N` 比较大时）。

因为字符数量少（`N` 比较小）时，C-A C-C C-V 这一套操作的代价相对比较高，可能不如一个个按 A；而当 `N` 比较大时，
后期 C-V 的收获肯定很大。这种情况下整个操作序列大致是：开头连按几个 A，然后 C-A C-C 组合再接若干 C-V，
然后再 C-A C-C 接着若干 C-V，循环下去。

换句话说，最后一次按键要么是 A 要么是 C-V。明确了这一点，可以通过这两种情况来设计算法：
```java
int[] dp = new int[N + 1];
// 定义：dp[i] 表示 i 次操作后最多能显示多少个 A
for (int i = 0; i <= N; i++) 
    dp[i] = max(
            这次按 A 键,
            这次按 C-V
        )
```

对于「按 A 键」这种情况，就是状态 `i - 1` 的屏幕上新增了一个 A 而已，很容易得到结果：
```java
dp[i] = dp[i - 1] + 1;
```

刚才说了，最优的操作序列一定是 C-A C-C 接着若干 C-V，所以我们用一个变量 `j` 作为若干 C-V 的起点。
那么 `j` 之前的 2 个操作就应该是 C-A C-C 了：
```java
public int maxA(int N) {
    int[] dp = new int[N + 1];
    for (int i = 1; i <= N; i++) {
        dp[i] = dp[i - 1] + 1;
        for (int j = 2; j < i; j++)
            dp[i] = Math.max(dp[i], dp[j - 2] * (i - j + 1));
    }
    return dp[N];
}
```

其中 `j` 变量减 2 是给 C-A C-C 留下操作数，看个图就明白了：

![操作序列][four-procedure]

这样，此算法就完成了，时间复杂度 O(N^2)，空间复杂度 O(N)，这种解法应该是比较高效的了。

### 3.3.3 总结

动态规划难就难在寻找状态转移，不同的定义可以产生不同的状态转移逻辑，虽然最后都能得到正确的结果，但是效率可能有巨大的差异。

回顾第一种解法，重叠子问题已经消除了，但是效率还是低，到底低在哪里呢？抽象出递归框架：
```python
def dp(n, a_num, copy):
    dp(n - 1, a_num + 1, copy),    # A
    dp(n - 1, a_num + copy, copy), # C-V
    dp(n - 2, a_num, a_num)        # C-A C-C
```

看这个穷举逻辑，是有可能出现这样的操作序列 C-A C-C，C-A C-C... 或者 C-V,C-V,...。显然这种操作序列的结果不是最优的，
但是我们并没有想办法规避这些情况的发生，从而增加了很多没必要的子问题计算。

回顾第二种解法，我们稍加思考，发现最优的序列应该是这种形式：A,A..C-A,C-C,C-V,C-V..C-A,C-C,C-V..。

根据这个事实，我们重新定义了状态，重新寻找了状态转移，**从逻辑上减少了无效的子问题个数，从而提高了算法的效率**。


[fib]: ../../../res/img/dp-fib.jpg
[fib-reduce]: ../../../res/img/dp-fib-reduce.jpg
[fib-graph]: ../../../res/img/dp-fib-graph.jpg
[fib-table]: ../../../res/img/dp-fib-table.jpg
[fib-function]: ../../../res/img/dp-fib-function.png
[coin-function]: ../../../res/img/dp-coin-function.png
[coin-tree]: ../../../res/img/dp-coin-tree.jpg
[four-title]: ../../../res/img/dp-four-title.jpg
[four-procedure]: ../../../res/img/dp-four-procedure.jpg

<b id="f1">\[1\]</b> https://labuladong.gitee.io/algo/动态规划系列/动态规划详解进阶.html [↩](#a1)  