# 1. 动态规划定义<sup id="a1">[\[1\]](#f1)</sup>

首先，**动态规划问题的一般形式就是求最值**。动态规划其实是运筹学的一种最优化方法，只不过在计算机问题上应用比较多，
比如说让你求最长递增子序列呀，最小编辑距离呀等等。

既然是要求最值，核心问题是什么呢？**求解动态规划的核心问题是穷举**。因为要求最值，肯定要把所有可行的答案穷举出来，
然后在其中找最值呗。

动态规划的求解有以下几个特点：
1. 动态规划的穷举有点特别，因为这类问题存在**重叠子问题**，如果暴力穷举的话效率会极其低下，所以需要**备忘录**
或者**DP table**来优化穷举过程，避免不必要的计算。
2. 而且，动态规划问题一定会具备**最优子结构**，才能通过子问题的最值得到原问题的最值。
要符合「最优子结构」，**子问题间必须互相独立**。子问题相互独立，就是问题**无后效性**，也就是说从不同的路径走到一个共同状态，
后续的状态变迁都是一样的，和之前采用何种路径到这个状态没有关系。即前面的各种决策结果由当前这个共同状态表示，
在考虑后半段的决策方面没有任何区别，“未来与过去无关”。
3. 另外，虽然动态规划的核心思想就是穷举求最值，但是问题可以千变万化，穷举所有可行解其实并不是一件容易的事，
只有列出正确的**状态转移方程**才能正确地穷举。

以上提到的就是**动态规划三要素：重叠子问题、最优子结构、状态转移方程**。在实际的算法问题中，**写出状态转移方程是最困难的**。
可以看到，**动态规划的核心设计思想是数学归纳法**。

**对于动态规划问题，首先要明白有哪些「状态」，有哪些「选择」**。除了思考「状态」和「选择」，我们也可以思考**子问题的定义**。

下面是一个思维框架，辅助你思考状态转移方程。**明确「状态」-> 明确「选择」 -> 明确 base case -> 定义 dp 数组/函数的含义**。
按上面的套路走，最后的结果就可以套这个框架：
```python
# 初始化 base case
dp[0][0][...] = base
# 进行状态转移
for 状态1 in 状态1的所有取值：
    for 状态2 in 状态2的所有取值：
        for ...
            dp[状态1][状态2][...] = 求最值(选择1，选择2...)
```

# 2. 两个例子

## 2.1 斐波那契数列

请读者不要嫌弃这个例子简单，只有简单的例子才能让你把精力充分集中在算法背后的通用思想和技巧上，
而不会被那些隐晦的细节问题搞的莫名其妙。

### 2.1.1 暴力递归解法

斐波那契数列的数学形式就是递归的，写成代码就是这样：
```java
int fib(int N) {
    if (N == 1 || N == 2) return 1;
    return fib(N - 1) + fib(N - 2);
}
```

这个不用多说了，学校老师讲递归的时候似乎都是拿这个举例。我们也知道这样写代码虽然简洁易懂，但是十分低效，低效在哪里？
假设 `n = 20`，请画出递归树：

![斐波那契数列][fib]

想要计算原问题 f(20)，我就得先计算出子问题 f(19) 和 f(18)，然后要计算 f(19)，我就要先算出子问题 f(18) 和 f(17)，以此类推。
最后遇到 f(1) 或者 f(2) 的时候，结果已知，就能直接返回结果，递归树不再向下生长了。

**递归算法的时间复杂度怎么计算？就是用子问题个数乘以解决一个子问题需要的时间**。
1. 首先计算子问题个数，即递归树中节点的总数。显然二叉树节点总数为指数级别，所以子问题个数为 O(2^n)。
2. 然后计算解决一个子问题的时间，在本算法中，没有循环，只有 f(n - 1) + f(n - 2) 一个加法操作，时间为 O(1)。
3. 所以，这个算法的时间复杂度为二者相乘，即 O(2^n)，指数级别，爆炸。

观察递归树，很明显发现了算法低效的原因：存在大量重复计算，比如 f(18) 被计算了两次，而且你可以看到，以 f(18) 为根的这个递归树体量巨大，
多算一遍，会耗费巨大的时间。更何况，还不止 f(18) 这一个节点被重复计算，所以这个算法及其低效。

这就是动态规划问题的第一个性质：**重叠子问题**。下面，我们想办法解决这个问题。

### 2.1.2 带备忘录的递归解法

明确了问题，其实就已经把问题解决了一半。即然耗时的原因是重复计算，那么我们可以造一个**备忘录**，
每次算出某个子问题的答案后别急着返回，先记到「备忘录」里再返回；每次遇到一个子问题先去「备忘录」里查一查，
如果发现之前已经解决过这个问题了，直接把答案拿出来用，不要再耗时去计算了。

一般使用一个数组充当这个「备忘录」，当然你也可以使用哈希表（字典），思想都是一样的：
```java
int fib(int N) {
    if (N < 1) 
        return 0;

    // 备忘录全初始化为 0
    int[] memo[N + 1];

    // 进行带备忘录的递归
    return helper(memo, N);
}

int helper(int[] memo, int n) {
    // base case
    if (n == 1 || n == 2) 
        return 1;

    // 已经计算过
    if (memo[n] != 0) 
        return memo[n];

    memo[n] = helper(memo, n - 1) + helper(memo, n - 2);

    return memo[n];
}
```

现在，画出递归树，你就知道「备忘录」到底做了什么：

![使用备忘录后的斐波那契数列][fib-reduce]

实际上，带「备忘录」的递归算法，把一棵存在巨量冗余的递归树通过**剪枝**，改造成了一幅**不存在冗余的递归图**，
极大减少了子问题（即递归图中节点）的个数：

![斐波那契数列递归图][fib-graph]

**递归算法的时间复杂度怎么计算？就是用子问题个数乘以解决一个子问题需要的时间**：
1. 子问题个数，即图中节点的总数，由于本算法不存在冗余计算，子问题就是 f(1), f(2), f(3) ... f(20)，
数量和输入规模 n = 20 成正比，所以子问题个数为 O(n)。
2. 解决一个子问题的时间，同上，没有什么循环，时间为 O(1)。
3. 所以，本算法的时间复杂度是 O(n)。比起暴力算法，是降维打击。

至此，带备忘录的递归解法的效率已经和迭代的动态规划解法一样了。实际上，这种解法和迭代的动态规划已经差不多了，
只不过这种方法叫做**自顶向下**，动态规划叫做**自底向上**。
 - 啥叫「自顶向下」？注意我们刚才画的递归树（或者说图），是从上向下延伸，都是从一个规模较大的原问题比如说 f(20)，
 向下逐渐分解规模，直到 f(1) 和 f(2) 这两个 base case，然后逐层返回答案，这就叫「自顶向下」。
 - 啥叫「自底向上」？反过来，我们直接从最底下，最简单，问题规模最小的 f(1) 和 f(2) 开始往上推，直到推到我们想要的答案 f(20)，
 这就是动态规划的思路，这也是为什么动态规划一般都脱离了递归，而是由循环迭代完成计算。

### 2.1.3 dp 数组的迭代解法

有了上一步「备忘录」的启发，我们可以把这个「备忘录」独立出来成为一张表，就叫做 **DP table** 吧，
在这张表上完成「自底向上」的推算岂不美哉！
```java
int fib(int N) {
    if (N < 1) 
        return 0;
    if (N == 1 || N == 2) 
        return 1;

    int[] dp[N + 1];
    // base case
    dp[1] = dp[2] = 1;
    for (int i = 3; i <= N; i++)
        dp[i] = dp[i - 1] + dp[i - 2];
    return dp[N];
}
```

下面是解释图，而且你发现这个 DP table 特别像之前那个「剪枝」后的结果，只是反过来算而已。实际上，
带备忘录的递归解法中的「备忘录」，最终完成后就是这个 DP table，所以说这两种解法其实是差不多的，
大部分情况下，效率也基本相同。

![DP table][fib-table]

### 2.1.4 状态方程

这里，引出「状态转移方程」这个名词，实际上就是描述问题结构的数学形式：

![斐波那契数列状态方程][fib-function]

为啥叫「状态转移方程」？其实就是为了听起来高端。你把 f(n) 想做一个状态 n，这个状态 n 是由状态 n - 1 和状态 n - 2 相加转移而来，
这就叫**状态转移**，仅此而已。

你会发现，上面的几种解法中的所有操作，例如 `return f(n - 1) + f(n - 2)，dp[i] = dp[i - 1] + dp[i - 2]`，
以及对备忘录或 DP table 的初始化操作，都是围绕这个方程式的不同表现形式。**可见列出状态转移方程的重要性，它是解决问题的核心**。
而且很容易发现，其实状态转移方程直接代表着暴力解法。

千万不要看不起暴力解，动态规划问题最困难的就是写出这个暴力解，即状态转移方程。只要写出暴力解，
优化方法无非是用备忘录或者 DP table，再无奥妙可言。

### 2.1.5 状态压缩

这个例子的最后，讲一个细节优化。细心的读者会发现，**根据斐波那契数列的状态转移方程，当前状态只和之前的两个状态有关**，
其实并不需要那么长的一个 DP table 来存储所有的状态，只要想办法存储之前的两个状态就行了。所以，可以进一步优化，
把空间复杂度降为 O(1)：
```java
int fib(int n) {
    if (n < 1) return 0;
    if (n == 2 || n == 1) 
        return 1;
    int prev = 1, curr = 1;
    for (int i = 3; i <= n; i++) {
        int sum = prev + curr;
        prev = curr;
        curr = sum;
    }
    return curr;
}
```

这个技巧就是所谓的**状态压缩**，如果我们发现每次状态转移只需要 DP table 中的一部分，
那么可以尝试用状态压缩来缩小 DP table 的大小，只记录必要的数据，上述例子就相当于把DP table 的大小从 n 缩小到 2。
后续的动态规划章节中我们还会看到这样的例子，一般来说是把一个二维的 DP table 压缩成一维，
即把空间复杂度从 O(n^2) 压缩到 O(n)。

有人会问，动态规划的另一个重要特性「最优子结构」，怎么没有涉及？下面会涉及。斐波那契数列的例子严格来说不算动态规划，
因为没有涉及求最值，以上旨在说明重叠子问题的消除方法，演示得到最优解法逐步求精的过程。下面，看第二个例子，凑零钱问题。

## 2.2 凑零钱问题

先看下题目：给你 `k` 种面值的硬币，面值分别为 `c1, c2 ... ck`，每种硬币的数量无限，再给一个总金额 `amount`，
问你最少需要几枚硬币凑出这个金额，如果不可能凑出，算法返回 -1 。算法的函数签名如下：
```java
// coins 中是可选硬币面值，amount 是目标金额
int coinChange(int[] coins, int amount);
```

比如说 `k = 3`，面值分别为 1，2，5，总金额 `amount = 11`。那么最少需要 3 枚硬币凑出，即 11 = 5 + 5 + 1。

你认为计算机应该如何解决这个问题？显然，就是把所有可能的凑硬币方法都穷举出来，然后找找看最少需要多少枚硬币。

### 2.2.1 暴力递归解法——列出正确的状态转移方程

首先，这个问题是动态规划问题，因为它具有**最优子结构**的。要符合「最优子结构」，子问题间必须互相独立。
啥叫相互独立？你肯定不想看数学证明，我用一个直观的例子来讲解。

比如说，假设你考试，每门科目的成绩都是互相独立的。你的原问题是考出最高的总成绩，那么你的子问题就是要把语文考到最高，
数学考到最高…… 为了每门课考到最高，你要把每门课相应的选择题分数拿到最高，填空题分数拿到最高…… 当然，最终就是你每门课都是满分，
这就是最高的总成绩。

得到了正确的结果：最高的总成绩就是总分。因为这个过程符合最优子结构，“每门科目考到最高”这些子问题是互相独立，互不干扰的。

但是，如果加一个条件：你的语文成绩和数学成绩会互相制约，数学分数高，语文分数就会降低，反之亦然。这样的话，
显然你能考到的最高总成绩就达不到总分了，按刚才那个思路就会得到错误的结果。因为子问题并不独立，语文数学成绩无法同时最优，
所以最优子结构被破坏。

回到凑零钱问题，为什么说它符合最优子结构呢？比如你想求 `amount = 11` 时的最少硬币数（原问题），
如果你知道凑出 `amount = 10` 的最少硬币数（子问题），你只需要把子问题的答案加一（再选一枚面值为 1 的硬币）就是原问题的答案。
因为硬币的数量是没有限制的，所以子问题之间没有相互制，是互相独立的。

那么，既然知道了这是个动态规划问题，就要思考如何列出正确的状态转移方程：
1. **明确「base case」**。这个很简单，显然目标金额 `amount` 为 0 时算法返回 0，因为不需要任何硬币就已经凑出目标金额了。
2. **明确「状态」，也就是原问题和子问题中会变化的变量**。我们需要知道什么信息，才能将原问题分解为规模更小的子问题？
由于硬币数量无限，硬币的面额也是题目给定的，只有目标金额会不断地向 base case 靠近，所以唯一的「状态」就是目标金额 `amount`。
需要注意，**好的状态定义可以从逻辑上减少无效的子问题个数，也就是缩减状态空间**，从而提高算法的效率
3. **明确「选择」，也就是导致「状态转移」的行为**。目标金额为什么变化呢，因为你在选择硬币，你每选择一枚硬币，
就相当于减少了目标金额。所以说所有硬币的面值，就是你的「选择」。
**动态规划是一个穷举过程，所有的选择都要试一遍（但也可能会有剪枝优化）**。
4. **明确 dp 函数/数组的定义**。我们这里讲的是自顶向下的解法，所以会有一个递归的 dp 函数，
一般来说函数的参数就是状态转移中会变化的量，也就是上面说到的「状态」；函数的返回值就是题目要求我们计算的量。
就本题来说，状态只有一个，即「目标金额」，题目要求我们计算凑出目标金额所需的最少硬币数量。**对于 dp 数组，还要明确初始值，
以及从上一次中继承什么状态**。所以我们可以这样定义 dp 函数：
    > `dp(n)` 的定义：输入一个目标金额 `n`，返回凑出目标金额 `n` 的最少硬币数量。

搞清楚上面这几个关键点，解法的伪码就可以写出来了：
```java
// 伪码框架
int coinChange(int[] coins, int amount) {
    // 题目要求的最终结果是 dp(amount)
    return dp(int[] coins, amount)
}

// 定义：要凑出金额 n，至少要 dp(n) 个硬币
int dp(int[] coins, int amount) {
    // 做选择，选择需要硬币最少的那个结果
    for (int coin: coins)
        res = min(res, 1 + dp(n - coin));
    return res
}
```

根据伪码，我们加上 base case 即可得到最终的答案。显然目标金额为 0 时，所需硬币数量为 0；当目标金额小于 0 时，无解，返回 -1：
```java
public int coinChange(int[] coins, int amount) {
    return dp(coins, amount);
}

private int dp(int[] coins, int amount) {
    // 基准条件
    if (amount == 0)
        return 0;
    if (amount < 0)
        return -1;

    // 自顶向下求解
    int res = Integer.MAX_VALUE;
    for (int coin : coins) {
        int subSolution = dp(coins, amount - coin, memory);
        // 跳过没有解的子问题
        if (subSolution == -1)
            continue;
        // 不要忘了加 1
        res = Math.min(res, 1 + subSolution);
    }
    
    // 所有子问题都无解，则最终无解
    return res != Integer.MAX_VALUE ? res : -1;
}
```

至此，状态转移方程其实已经完成了，以上算法已经是暴力解法了，以上代码的数学形式就是状态转移方程：

![凑零钱自顶向下 dp][coin-function]

至此，这个问题其实就解决了，只不过需要消除一下重叠子问题，比如 `amount = 11, coins = {1,2,5}` 时画出递归树看看：

![凑零钱递归树][coin-tree]

递归算法的时间复杂度分析：子问题总数 x 每个子问题的时间。
子问题总数为递归树节点个数，这个比较难看出来，是 O(n^k)，总之是指数级别的。每个子问题中含有一个 for 循环，复杂度为 O(k)。
所以总时间复杂度为 O(k * n^k)，指数级别。

### 2.2.2 带备忘录的递归解法

类似之前斐波那契数列的例子，只需要稍加修改，就可以通过备忘录消除子问题：
```java
public int coinChange(int[] coins, int amount) {
    // 状态是金额，结果是凑成这个金额所需的最少硬币数。
    // 因为不管选择哪个硬币，造成的结果类型都是相同的，所以选用一维数组。
    int[] memory = new int[amount + 1];
    // 因为凑成 amount 金额的硬币数最多只可能等于 amount（全用 1 元面值的硬币），
    // 所以初始化为 amount + 1 就相当于初始化为正无穷，便于后续取最小值。
    Arrays.fill(memory, amount + 1);
    return dp(coins, amount, memory);
}

private int dp(int[] coins, int amount, int[] memory) {
    // 基准条件
    if (amount == 0)
        return 0;
    if (amount < 0)
        return -1;

    // 保存的子问题
    int exist = memory[amount];
    if (exist != memory.length)
        return exist;

    // 自顶向下求解
    int res = memory.length;
    for (int coin : coins) {
        int subSolution = dp(coins, amount - coin, memory);
        // 跳过没有解的子问题
        if (subSolution == -1)
            continue;
        // 不要忘了加 1
        res = Math.min(res, 1 + subSolution);
    }
    // 所有子问题都无解，则最终无解
    res = res != memory.length ? res : -1;
    // 保存子问题的解
    memory[amount] = res;

    return res;
}
```

不画图了，很显然「备忘录」大大减小了子问题数目，完全消除了子问题的冗余，所以子问题总数不会超过金额数 n，即子问题数目为 O(n)。
处理一个子问题的时间不变，仍是 O(k)，所以总的时间复杂度是 O(kn)。

### 2.2.3 dp 数组的迭代解法

当然，我们也可以自底向上使用 dp table 来消除重叠子问题，关于「状态」「选择」和 base case 与之前没有区别，
`dp` 数组的定义和刚才 `dp` 函数类似，也是把「状态」，也就是目标金额作为变量。不过 `dp` 函数体现在函数参数，
而 `dp` 数组体现在数组索引：
> `dp` 数组的定义：当目标金额为 `i` 时，至少需要 `dp[i]` 枚硬币凑出。

根据我们文章开头给出的动态规划代码框架可以写出如下解法：
```java
public int coinChange(int[] coins, int amount) {
    if (amount == 0)
        return 0;
    // dp table 大小为 amount + 1，初始值为 amount + 1
    int[] dp = new int[amount + 1];
    Arrays.fill(dp, amount + 1);
    // base case
    dp[0] = 0;
    // 外层 for 循环在遍历所有状态的所有取值
    for (int status = 0; status < dp.length; status++) {
        // 内层 for 循环在求所有选择的最小值
        for (int coin : coins) {
            // 子问题无解，跳过
            if (status - coin < 0)
                continue;
            dp[status] = Math.min(dp[status], 1 + dp[status - coin]);
        }
    }

    return dp[amount] == amount + 1 ? -1 : dp[amount];
}
```

上面其实是状态压缩后的代码，为了第 6 节背包问题保持一致，可以看看 [E322_Medium_CoinChange][coin-java] 中未压缩的代码。

# 3. 最优子结构详解

## 3.1 定义

「最优子结构」是某些问题的一种特定性质，并不是动态规划问题专有的。也就是说，很多问题其实都具有最优子结构，只是其中大部分不具有重叠子问题，
所以我们不把它们归为动态规划系列问题而已。

我先举个很容易理解的例子：假设你们学校有 10 个班，你已经计算出了每个班的最高考试成绩。那么现在我要求你计算全校最高的成绩，你会不会算？
当然会，而且你不用重新遍历全校学生的分数进行比较，而是只要在这 10 个最高成绩中取最大的就是全校的最高成绩。

我给你提出的这个问题就符合最优子结构：可以从子问题的最优结果推出更大规模问题的最优结果。让你算每个班的最优成绩就是子问题，
你知道所有子问题的答案后，就可以借此推出全校学生的最优成绩这个规模更大的问题的答案。

你看，这么简单的问题都有最优子结构性质，只是因为显然没有重叠子问题，所以我们简单地求最值肯定用不出动态规划。

## 3.2 改造问题

再举个例子：假设你们学校有 10 个班，你已知每个班的最大分数差（最高分和最低分的差值）。那么现在我让你计算全校学生中的最大分数差，
你会不会算？可以想办法算，但是肯定不能通过已知的这 10 个班的最大分数差推到出来。
因为这 10 个班的最大分数差不一定就包含全校学生的最大分数差，比如全校的最大分数差可能是 3 班的最高分和 6 班的最低分之差。

那么遇到这种最优子结构失效情况，怎么办？策略是：**改造问题**。对于最大分数差这个问题，我们不是没办法利用已知的每个班的分数差吗，
那我只能这样写一段暴力代码：
```java
int result = 0;
for (Student a : school) {
    for (Student b : school) {
        if (a == b)
            continue;
        result = max(result, |a.score - b.score|);
    }
}
return result;
```

改造问题，也就是把问题等价转化：最大分数差，不就等价于最高分数和最低分数的差么，那不就是要求最高和最低分数么，
不就是我们讨论的第一个问题么，不就具有最优子结构了么？那现在改变思路，借助最优子结构解决最值问题，再回过头解决最大分数差问题，
是不是就高效多了？

当然，上面这个例子太简单了，不过请读者回顾一下，我们做动态规划问题，是不是一直在求各种最值，本质跟我们举的例子没啥区别，
无非需要处理一下重叠子问题。

## 3.3 例 1：4 键键盘

**对 dp 数组的不同定义需要完全不同的逻辑，从而产生完全不同的解法**。

首先看一下题目：

![4键键盘][four-title]

如何在 N 次敲击按钮后得到最多的 A？我们穷举呗，对于每次按键，我们可以穷举四种可能，很明显就是一个动态规划问题。

### 3.3.1 第一种思路

这种思路会很容易理解，但是效率并不高，我们直接走流程：**对于动态规划问题，首先要明白有哪些「状态」，有哪些「选择」**。

具体到这个问题，对于每次敲击按键，有哪些「选择」是很明显的：4 种，就是题目中提到的四个按键，
分别是 A、C-A、C-C、C-V（Ctrl 简写为 C）。

接下来，思考一下对于这个问题有哪些「状态」？或者换句话说，**我们需要知道什么信息，才能将原问题分解为规模更小的子问题？**

你看我这样定义三个状态行不行：第一个状态是剩余的按键次数，用 `n` 表示；第二个状态是当前屏幕上字符 A 的数量，
用 `a_num` 表示；第三个状态是剪切板中字符 A 的数量，用 `copy` 表示。

如此定义「状态」，就可以知道 base case：当剩余次数 `n` 为 0 时，`a_num` 就是我们想要的答案。

结合刚才说的 4 种「选择」，我们可以把这几种选择通过状态转移表示出来：
```
dp(n - 1, a_num + 1, copy),    # A
解释：按下 A 键，屏幕上加一个字符
同时消耗 1 个操作数

dp(n - 1, a_num + copy, copy), # C-V
解释：按下 C-V 粘贴，剪切板中的字符加入屏幕
同时消耗 1 个操作数

dp(n - 2, a_num, a_num)        # C-A C-C
解释：全选和复制必然是联合使用的，
剪切板中 A 的数量变为屏幕上 A 的数量
同时消耗 2 个操作数
```

这样可以看到问题的规模 `n` 在不断减小，肯定可以到达 `n = 0` 的 base case，所以这个思路是正确的：
```java
class Status implements Comparable<Status> {
    
    int n, aNum, copy;

    Status(int n, int aNum, int copy) {
        this.n = n;
        this.aNum = aNum;
        this.copy = copy;
    }

    public int compareTo(Status o) {
        int cmp = Integer.compare(n, o.n);
        return cmp != 0 
                ? cmp 
                : (cmp = Integer.compare(aNum, o.aNum)) != 0 ? cmp : Integer.compare(copy, o.copy);
    }
}

public int firstMethod(int N) {
    return dp(N, 0, 0, new HashMap<>());
}

private int dp(int N, int aNum, int copy, Map<Status, Integer> memory) {
    if (N <= 0)
        return aNum;
    Status s = new Status(N, aNum, copy);
    int max = memory.getOrDefault(s, -1);
    if (max != -1)
        return max;
    max = Math.max(dp(N - 1, aNum + 1, copy, memory),       // A
            Math.max(dp(N - 1, aNum + copy, copy, memory),  // C-A
                    dp(N - 2, aNum, aNum, memory)));        // C-A C-C
    memory.put(s, max);

    return max;
}
```

尝试分析一下这个算法的时间复杂度，就会发现不容易分析。我们可以把这个 `dp` 函数写成 `dp` 数组：
```
dp[n][a_num][copy]
# 状态的总数（时空复杂度）就是这个三维数组的体积
```

我们知道变量 `n` 最多为 `N`，但是 `a_num` 和 `copy` 最多为多少我们很难计算，复杂度起码也有 O(N^3) 吧。
所以这个算法并不好，复杂度太高，且已经无法优化了。

### 3.3.2 第二种思路

这种思路稍微有点复杂，但是效率高。继续走流程，「选择」还是那 4 个，但是这次我们只定义一个「状态」，也就是剩余的敲击次数 `n`。

这个算法基于这样一个事实，最优按键序列一定只有两种情况：
1. 要么一直按 A：A,A,…A（当 `N` 比较小时）。
2. 要么是这么一个形式：A,A,…C-A,C-C,C-V,C-V,…C-V（当 `N` 比较大时）。

因为字符数量少（`N` 比较小）时，C-A C-C C-V 这一套操作的代价相对比较高，可能不如一个个按 A；而当 `N` 比较大时，
后期 C-V 的收获肯定很大。这种情况下整个操作序列大致是：开头连按几个 A，然后 C-A C-C 组合再接若干 C-V，
然后再 C-A C-C 接着若干 C-V，循环下去。

换句话说，最后一次按键要么是 A 要么是 C-V。明确了这一点，可以通过这两种情况来设计算法：
```java
int[] dp = new int[N + 1];
// 定义：dp[i] 表示 i 次操作后最多能显示多少个 A
for (int i = 0; i <= N; i++) 
    dp[i] = max(
            这次按 A 键,
            这次按 C-V
        )
```

对于「按 A 键」这种情况，就是状态 `i - 1` 的屏幕上新增了一个 A 而已，很容易得到结果：
```java
dp[i] = dp[i - 1] + 1;
```

刚才说了，最优的操作序列一定是 C-A C-C 接着若干 C-V，所以我们用一个变量 `j` 作为若干 C-V 的起点。
那么 `j` 之前的 2 个操作就应该是 C-A C-C 了：
```java
public int maxA(int N) {
    int[] dp = new int[N + 1];
    for (int i = 1; i <= N; i++) {
        dp[i] = dp[i - 1] + 1;
        for (int j = 2; j < i; j++)
            dp[i] = Math.max(dp[i], dp[j - 2] * (i - j + 1));
    }
    return dp[N];
}
```

其中 `j` 变量减 2 是给 C-A C-C 留下操作数，看个图就明白了：

![操作序列][four-procedure]

这样，此算法就完成了，时间复杂度 O(N^2)，空间复杂度 O(N)，这种解法应该是比较高效的了。

### 3.3.3 总结

动态规划难就难在寻找状态转移，不同的定义可以产生不同的状态转移逻辑，虽然最后都能得到正确的结果，但是效率可能有巨大的差异。

回顾第一种解法，重叠子问题已经消除了，但是效率还是低，到底低在哪里呢？抽象出递归框架：
```python
def dp(n, a_num, copy):
    dp(n - 1, a_num + 1, copy),    # A
    dp(n - 1, a_num + copy, copy), # C-V
    dp(n - 2, a_num, a_num)        # C-A C-C
```

看这个穷举逻辑，是有可能出现这样的操作序列 C-A C-C，C-A C-C... 或者 C-V,C-V,...。显然这种操作序列的结果不是最优的，
但是我们并没有想办法规避这些情况的发生，从而增加了很多没必要的子问题计算。

回顾第二种解法，我们稍加思考，发现最优的序列应该是这种形式：A,A..C-A,C-C,C-V,C-V..C-A,C-C,C-V..。

根据这个事实，我们重新定义了状态，重新寻找了状态转移，**从逻辑上减少了无效的子问题个数，从而提高了算法的效率**。

## 3.4 例 2：高楼扔鸡蛋

题目是这样：你面前有一栋从 1 到 `N` 共 `N` 层的楼，然后给你 `K` 个鸡蛋（`K` 至少为 1）。现在确定这栋楼存在楼层 `0<=F<=N`，
在这层楼将鸡蛋扔下去，鸡蛋恰好没摔碎（高于 `F` 的楼层都会碎，低于 `F` 的楼层都不会碎）。现在问你，**最坏情况下**，
你至少要扔几次鸡蛋，才能确定这个楼层 `F` 呢？

PS：`F` 可以为 0，比如说鸡蛋在 1 层都能摔碎，那么 `F = 0`。

### 3.4.1 解析题目

也就是让你找摔不碎鸡蛋的最高楼层 `F`，但什么叫「最坏情况」下「至少」要扔几次呢？我们分别举个例子就明白了。

比方说现在先不管鸡蛋个数的限制，有 7 层楼，你怎么去找鸡蛋恰好摔碎的那层楼？最原始的方式就是线性扫描：我先在 1 楼扔一下，没碎，
我再去 2 楼扔一下，没碎，我再去 3 楼……。以这种策略，最坏情况应该就是我试到第 7 层鸡蛋也没碎（`F = 7`），也就是我扔了 7 次鸡蛋。

现在你应该理解什么叫做「最坏情况」下了，**鸡蛋破碎一定发生在搜索区间穷尽时**，不会说你在第 1 层摔一下鸡蛋就碎了，这是你运气好，
不是最坏情况。

现在再来理解一下什么叫「至少」要扔几次。依然不考虑鸡蛋个数限制，同样是 7 层楼，我们可以优化策略。
最好的策略是使用二分查找思路，我先去第 `(1 + 7) / 2 = 4` 层扔一下：
 - 如果碎了说明 `F` 小于 4，我就去第 `(1 + 3) / 2 = 2` 层试……
 - 如果没碎说明 `F` 大于等于 4，我就去第 `(5 + 7) / 2 = 6` 层试……

以这种策略，最坏情况应该是试到第 7 层鸡蛋还没碎（`F = 7`），或者鸡蛋一直碎到第 1 层（`F = 0`）。
然而无论那种最坏情况，只需要试 `log7` 向上取整等于 3 次，比刚才的 7 次要少，这就是所谓的至少要扔几次。

实际上，如果不限制鸡蛋个数的话，二分思路显然可以得到最少尝试的次数，但问题是，现在给你了鸡蛋个数的限制 `K`，直接使用二分思路就不行了。

比如说只给你 1 个鸡蛋，7 层楼，你敢用二分吗？你直接去第 4 层扔一下，如果鸡蛋没碎还好，但如果碎了你就没有鸡蛋继续测试了，
无法确定鸡蛋恰好摔不碎的楼层 `F` 了。这种情况下只能用线性扫描的方法，算法返回结果应该是 7。

有的读者也许会有这种想法：二分查找排除楼层的速度无疑是最快的，那干脆先用二分查找，等到只剩 1 个鸡蛋的时候再执行线性扫描，
这样得到的结果是不是就是最少的扔鸡蛋次数呢？很遗憾，并不是，比如说把楼层变高一些，100 层，给你 2 个鸡蛋，你在 50 层扔一下，碎了，
那就只能线性扫描 1～49 层了，最坏情况下要扔 50 次。

如果不要「二分」，变成「五分」「十分」都会大幅减少最坏情况下的尝试次数。比方说第一个鸡蛋每隔十层楼扔，
在哪里碎了第二个鸡蛋一个个线性扫描，总共不会超过 20 次。

最优解其实是 14 次。最优策略非常多，而且并没有什么规律可言。

### 3.4.2 思路分析

对动态规划问题，直接套我们以前多次强调的框架即可：**这个问题有什么「状态」，有什么「选择」，然后穷举**。

「状态」很明显，就是当前拥有的鸡蛋数 `K` 和需要测试的楼层数 `N`。随着测试的进行，鸡蛋个数可能减少，楼层的搜索范围会减小，
这就是状态的变化。

「选择」其实就是去选择哪层楼扔鸡蛋。回顾刚才的线性扫描和二分思路，二分查找每次选择到楼层区间的中间去扔鸡蛋，
而线性扫描选择一层层向上测试。不同的选择会造成状态的转移。

现在明确了「状态」和「选择」，动态规划的基本思路就形成了：肯定是个二维的 `dp` 数组或者带有两个状态参数的 `dp` 函数来表示状态转移；
外加一个 `for` 循环来遍历所有选择，择最优的选择更新结果：
```python
# 当前状态为 (K 个鸡蛋，N 层楼)
# 返回这个状态下的最优结果
def dp(K, N):
    int res
    for 1 <= i <= N:
        res = min(res, 这次在第 i 层楼扔鸡蛋)
    return res
```
这段伪码还没有展示递归和状态转移，不过大致的算法框架已经完成了。

我们在第 `i` 层楼扔了鸡蛋之后，可能出现两种情况：鸡蛋碎了，鸡蛋没碎。注意，**这时候状态转移就来了**：
 - 如果鸡蛋碎了，那么鸡蛋的个数 `K` 应该减一，搜索的楼层区间应该从 `[1..N]` 变为 `[1..i-1]` 共 `i-1` 层楼；
 - 如果鸡蛋没碎，那么鸡蛋的个数 `K` 不变，搜索的楼层区间应该从 `[1..N]` 变为 `[i+1..N]` 共 `N-i` 层楼。

细心的读者可能会问，在第 `i` 层楼扔鸡蛋如果没碎，楼层的搜索区间缩小至上面的楼层，是不是应该包含第 `i` 层楼呀？不必，因为已经包含了。
开头说了 `F` 是可以等于 0 的，向上递归后，第 `i` 层楼其实就相当于第 0 层，可以被取到，所以说并没有错误。

因为我们要求的是最坏情况下扔鸡蛋的次数，所以鸡蛋在第i层楼碎没碎，取决于那种情况的结果更大：
```python
def dp(K, N):
    for 1 <= i <= N:
        # 最坏情况下的最少扔鸡蛋次数
        res = min(res, 
                  max( 
                        dp(K - 1, i - 1), # 碎
                        dp(K, N - i)      # 没碎
                     ) + 1 # 在第 i 楼扔了一次
                 )
    return res
```

递归的 base case 很容易理解：当楼层数 `N` 等于 0 时，显然不需要扔鸡蛋；当鸡蛋数 `K` 为 1 时，显然只能线性扫描所有楼层：
```python
def dp(K, N):
    if K == 1: return N
    if N == 0: return 0
    ...
```

至此，其实这道题就解决了！只要添加一个备忘录消除重叠子问题即可：
```java
public int superEggDrop(int k, int n) {
    int[][] dp = new int[k + 1][n + 1];
    return dp(k, n, dp);
}

private int dp(int k, int n, int[][] dp) {
    if (dp[k][n] != 0)
        return dp[k][n];
    if (k == 1 || n == 0)
        return n;
    int res = n + 1;
    // 找出最坏情况下的最少扔鸡蛋次数
    for (int i = 1; i <= n; i++)
        res = Math.min(res,
                // 状态转移
                Math.max(dp(k, n - i, dp),         // 没碎
                        dp(k - 1, i - 1, dp))   // 碎了
                        + 1);                        // 在第 i 楼扔了一次
    dp[k][n] = res;
    return res;
}
```

这个算法的时间复杂度是多少呢？**动态规划算法的时间复杂度就是子问题个数 × 函数本身的复杂度**。
 - 函数本身的复杂度就是忽略递归部分的复杂度，这里 `dp` 函数中有一个 `for` 循环，所以函数本身的复杂度是 O(N)。
 - 子问题个数也就是不同状态组合的总数，显然是两个状态的乘积，也就是 O(KN)。
 - 所以算法的总时间复杂度是 O(K*N^2), 空间复杂度为子问题个数，即 O(KN)。

### 3.4.3 迭代解法

下面是迭代解法，注意初始值的设置：
```java
public int iterateMethod(int k, int n) {
    if (k == 1 || n == 1)
        return n;

    int[][] dp = new int[k + 1][n + 1];
    // 当 k == 0 || n == 0 时，dp[k][n] 等于 0
    // 当只有一个鸡蛋时，有多少楼层就得扔多少次
    for (int floor = 1; floor <= n; floor++) {
        // 注意不要赋值为 n！！
        dp[1][floor] = floor;
    }
    // 其他情况设为 n + 1，
    for (int eggNum = 2; eggNum <= k; eggNum++) {
        for (int floor = 1; floor <= n; floor++) {
            dp[eggNum][floor] = n + 1;
        }
    }

    // 三重循环，算法复杂度为 O(k * n^2)

    // 状态1：鸡蛋数量
    for (int eggNum = 2; eggNum <= k; eggNum++) {
        // 状态2：楼层数量
        for (int floorNum = 1; floorNum <= n; floorNum++) {
            // 选择：在每个楼层试一下
            for (int choose = 1; choose <= floorNum; choose++) {
                // 找出最坏情况下的最少扔鸡蛋次数
                dp[eggNum][floorNum] = Math.min(
                        dp[eggNum][floorNum],
                        Math.max(dp[eggNum][floorNum - choose],     // 没碎
                                dp[eggNum - 1][choose - 1])         // 碎了
                                + 1);                               // 在第 choose 楼扔了一次
            }
        }
    }

    return dp[k][n];
}
```

### 3.4.4 二分搜索优化

题目要求最坏情况下至少需要扔几次鸡蛋才能测出鸡蛋恰好摔不碎的楼层 `F`。首先简述一下原始动态规划的思路：
1. 暴力穷举尝试在所有楼层 `1 <= i <= N` 扔鸡蛋，每次选择尝试次数最少的那一层；
2. 每次扔鸡蛋有两种可能，要么碎，要么没碎；
3. 如果鸡蛋碎了，`F` 应该在第 `i` 层下面，否则，`F` 应该在第 `i` 层上面；
4. 鸡蛋是碎了还是没碎，取决于哪种情况下尝试次数更多，因为我们想求的是最坏情况下的结果。

也就是就是下面这个状态转移方程：

![状态转移方程][egg-function]

首先我们根据 `dp(K, N)` 数组的定义（有 `K` 个鸡蛋面对 `N` 层楼，最少需要扔 `dp(K, N)` 次），很容易知道 `K` 固定时，
这个函数随着 `N` 的增加一定是单调递增的，无论你策略多聪明，楼层增加的话，测试次数一定要增加。

那么注意 `dp(K - 1, i - 1)` 和 `dp(K, N - i)` 这两个函数，其中 `i` 是从 1 到 `N` 单增的，如果我们固定 `K` 和 `N`，
把这两个函数看做关于 `i` 的函数，前者随着 `i` 的增加应该也是单调递增的，而后者随着 `i` 的增加应该是单调递减的：

![函数图像][egg-func-graph]

这时候求二者的较大值，再求这些最大值之中的最小值，其实就是求这两条直线交点，也就是红色折线的最低点嘛。
熟悉二分搜索的同学肯定敏感地想到了，这不就是相当于求 Valley（山谷）值嘛，可以用二分查找来快速寻找这个点的，直接看代码吧，
整体的思路还是一样，只是加快了搜索速度：
```java
// 状态1：鸡蛋数量
for (int eggNum = 2; eggNum <= k; eggNum++) {
    // 状态2：楼层数量
    for (int floorNum = 1; floorNum <= n; floorNum++) {
        // 选择：使用二分搜索找两个线性函数相交值
        int lo = 1, hi = floorNum;
        while (lo <= hi) {
            int mid = (lo + hi) >>> 1;
            int broken = dp[eggNum - 1][mid - 1];
            int notBroken = dp[eggNum][floorNum - mid];
            if (broken > notBroken) {
                hi = mid - 1;
                dp[eggNum][floorNum] = Math.min(dp[eggNum][floorNum], broken + 1);
            } else {
                lo = mid + 1;
                dp[eggNum][floorNum] = Math.min(dp[eggNum][floorNum], notBroken + 1);
            }
        }
    }
}
```

函数本身的复杂度就是忽略递归部分的复杂度，这里 `dp` 函数中用了一个二分搜索，所以函数本身的复杂度是 O(logN)。
子问题个数也就是不同状态组合的总数，显然是两个状态的乘积，也就是 O(KN)。
所以算法的总时间复杂度是 `O(K*N*logN)`, 空间复杂度 O(KN)。效率上比之前的算法 O(KN^2) 要高效不少。

### 3.4.5 重写状态转移

不同的状态定义可以衍生出不同的解法，其解法和复杂程度都可能有巨大差异。这里就是一个很好的例子。

再回顾一下我们之前定义的 `dp` 数组含义：
```java
// 当前状态为 k 个鸡蛋，面对 n 层楼
// 这个状态下最少的扔鸡蛋次数为 m
dp[k][n] = m
```

按照这个定义，就是确定当前的鸡蛋个数和面对的楼层数，就知道最小扔鸡蛋次数。最终我们想要的答案就是 `dp(K, N)` 的结果。
**这种思路下，肯定要穷举所有可能的扔法的**，用二分搜索优化也只是做了「剪枝」，减小了搜索空间，但本质思路没有变，只不过是更聪明的穷举。

现在，我们稍微修改 `dp` 数组的定义，**确定当前的鸡蛋个数和最多允许的扔鸡蛋次数，就知道能够确定 F 的最高楼层数**。
有点绕口，具体来说是这个意思：
```java
/*
当前有 k 个鸡蛋，可以尝试扔 m 次鸡蛋
这个状态下，最坏情况下最多能确切测试一栋 n 层的楼

比如说 dp[1][7] = 7 表示：
现在有 1 个鸡蛋，允许你扔 7 次;
这个状态下最多给你 7 层楼，使得你可以确定楼层 F 使得鸡蛋恰好摔不碎（一层一层线性探查嘛）
*/
dp[k][m] = n
```

这其实就是我们原始思路的**一个「反向」版本**，我们先不管这种思路的状态转移怎么写，先来思考一下这种定义之下，最终想求的答案是什么？

我们最终要求的其实是扔鸡蛋次数 `m`，但是这时候 `m` 在状态之中而不是 `dp` 数组的结果，可以这样处理：
```java
int superEggDrop(int K, int N) {

    int m = 0;
    while (dp[K][m] < N) {
        m++;
        // 状态转移...
    }
    return m;
}
```
题目不是给你 `K` 鸡蛋，`N` 层楼，让你求最坏情况下最少的测试次数 `m` 吗？`while` 循环结束的条件是 `dp[K][m] == N`，
也就是给你 `K` 个鸡蛋，允许测试 `m` 次，最坏情况下最多能测试 `N` 层楼。

注意看这两段描述，是完全一样的！所以说这样组织代码是正确的，关键就是状态转移方程怎么找呢？
现在这种 `dp` 定义基于下面两个事实：
1. 无论你在哪层楼扔鸡蛋，鸡蛋只可能摔碎或者没摔碎，碎了的话就测楼下，没碎的话就测楼上。
2. 无论你上楼还是下楼，总的楼层数 = 楼上的楼层数 + 楼下的楼层数 + 1（当前这层楼）。

根据这个特点，可以写出下面的状态转移方程：  
`dp[k][m] = dp[k][m-1] + dp[k-1][m-1] + 1`
 - `dp[k][m - 1]` 就是楼上的楼层数，因为鸡蛋个数 `k` 不变，也就是鸡蛋没碎，扔鸡蛋次数 `m` 减一；
 - `dp[k - 1][m - 1]` 就是楼下的楼层数，因为鸡蛋个数 `k` 减一，也就是鸡蛋碎了，同时扔鸡蛋次数 `m` 减一。

这个 `m` 为什么要减一而不是加一？之前定义得很清楚，这个 `m` 是一个允许的次数上界，而不是扔了几次。

至此，整个思路就完成了，只要把状态转移方程填进框架即可：
```java
public int superEggDrop(int k, int n) {
    if (k == 1 || n == 1)
        return n;

    // 最坏情况下的最少扔鸡蛋次数
    int m = 0;
    // 这个 dp 数组的状态是 dp[鸡蛋数][最多允许的扔鸡蛋次数]，值是最多能确切测试多少层。
    // m 不会超过 n（线性扫描）
    int[][] dp = new int[k + 1][n + 1];
    // 时间复杂度：O(k * n)
    for (int i = 1; i <= k; i++) {
        for (m = 1; m <= n; m++) {
            dp[i][m] = dp[i][m - 1] + dp[i - 1][m - 1] + 1;
            if (dp[i][m] >= n)
                break;
        }
    }
    
    return m;
}
```
这个算法的时间复杂度是多少？很明显就是两个嵌套循环的复杂度 O(KN)。

另外注意到 `dp[k][m]` 转移只和左边和左上的两个状态有关，所以很容易优化成一维 `dp` 数组：
```java
public int superEggDrop(int k, int n) {
    if (k == 1 || n == 1)
        return n;

    // 状态压缩。注意，一般的状态压缩是压缩行，这里是压缩列。
    // 因为从列的视角看，列的第 i 个只用到了前一列的第 i - 1 和第 i 个元素
    int[] dp = new int[k + 1];
    int m;
    for (m = 0; dp[k] < n; ++m)
        // 需要注意，这里是从右到左进行，因为右边的状态依赖于左边的状态
        for (int i = k; i > 0; --i)
            dp[i] += dp[i - 1] + 1;
    return m;
}
```

# 4. 子序列动态规划

子序列类型的问题，穷举出所有可能的结果都不容易，而动态规划算法做的就是穷举 + 剪枝，它俩天生一对儿。所以可以说只要涉及子序列问题，
十有八九都需要动态规划来解决，往这方面考虑就对了。

## 4.1 例 1：最长公共子序列

最长公共子序列（Longest Common Subsequence，简称 LCS）是一道非常经典的面试题目，因为它的解法是典型的二维动态规划，
大部分比较困难的字符串问题都和这个问题一个套路，比如下一个例题“编辑距离”。而且，这个算法稍加改造就可以用于解决其他问题，
所以说 LCS 算法是值得掌握的。下面是题目：

![最长公共子序列][lcs]

### 4.1.1 明确 dp 数组的含义

**第一步，一定要明确 `dp` 数组的含义**。对于两个字符串的动态规划问题，套路是通用的。
对于两个字符串求子序列的问题，都是用两个指针 `i` 和 `j` 分别在两个字符串上移动，大概率是动态规划思路。

比如说对于字符串 `s1 = "babcde"` 和 `s2 = "ace"`，一般来说都要构造一个这样的 DP table：

![LCS DP table][lcs-table]

为了方便理解此表，我们暂时认为索引是从 1 开始的，待会的代码中只要稍作调整即可。其中，`dp[i][j]` 的含义是：
对于 `s1[1..i]` 和 `s2[1..j]`，它们的 LCS 长度是 `dp[i][j]`。

### 4.1.2 定义 base case

我们专门让索引为 0 的行和列表示空串，`dp[0][..]` 和 `dp[..][0]` 都应该初始化为 0，这就是 base case。

比如说，按照刚才 dp 数组的定义，`dp[0][3]=0` 的含义是：对于字符串 `""` 和 `"bab"`，其 LCS 的长度为 0。
因为有一个字符串是空串，它们的最长公共子序列的长度显然应该是 0。

### 4.1.3 找状态转移方程

这是动态规划最难的一步，不过好在这种字符串问题的套路都差不多，权且借这道题来聊聊处理这类问题的思路。

**状态转移说简单些就是做选择**，比如说这个问题，是求 `s1` 和 `s2` 的最长公共子序列，不妨称这个子序列为 `lcs`。
那么对于 `s1` 和 `s2` 中的每个字符，有什么选择？很简单，**两种选择，要么在 `lcs` 中，要么不在**。

![lcs][lcs-sub]

这个「在」和「不在」就是选择，关键是，应该如何选择呢？这个需要动点脑筋：如果某个字符应该在 `lcs` 中，
那么这个字符肯定同时存在于 `s1` 和 `s2` 中，因为 `lcs` 是最长公共子序列嘛。

所以本题的思路是这样：用两个指针 `i` 和 `j` 从后往前遍历 `s1` 和 `s2`，如果 `s1[i]==s2[j]`，那么这个字符一定在 `lcs` 中；
否则的话，`s1[i]` 和 `s2[j]` 这两个字符至少有一个不在 `lcs` 中，需要丢弃一个——因为 `i`、`j` 之前的 `lcs` 都已被计算出（根据递归的定义）。
这也是从后往前遍历 `s1` 和 `s2` 的原因。4.1.3.4 节的 dp 数组解法更能看出这一点。

你可能会问：当 `s1[i]` 和 `s2[j]` 不相等时，为什么不考虑它们都不在 `lcs` 中的情况呢？因为我们在求最大值，
`s1[i+1..]` 和 `s2[j+1..]` 的 `lcs` 长度，这个长度肯定是小于等于 `s1[i..]` 和 `s2[j+1..]` 中的 `lcs` 长度的，
因为 `s1[i+1..]` 比 `s1[i..]` 短，那从这里面算出的 `lcs` 当然也不可能更长。

先看一下递归解法，比较容易理解：
```java
public int longestCommonSubsequence(String text1, String text2) {
    return dp(text1, text1.length() - 1, text2, text2.length() - 1);
}

private int dp(String text1, int i, String text2, int j) {
    // 其中一个是空串
    if (i == -1 || j == -1)
        return 0;
    if (text1.charAt(i) == text2.charAt(j))
        // 找到一个 lcs 的元素，继续往前找
        return dp(text1, i - 1, text2, j - 1) + 1;
    else
        // 从两个里面选最长的
        return Math.max(dp(text1, i - 1, text2, j), dp(text1, i, text2, j - 1));
}
```

对于第一种情况，找到一个 `lcs` 中的字符，同时将 `i, j` 向前移动一位，并给 `lcs` 的长度加一；
对于后者，则尝试两种情况，取更大的结果。

### 4.1.4 dp 数组的迭代解法

我们也很容易写出迭代解法。如下所示：
```java
public int longestCommonSubsequence(String text1, String text2) {
    final int m = text1.length(), n = text2.length();
    final int[][] dp = new int[m + 1][n + 1];
    
    for (int i = 1; i <= m; i++) {
        for (int j = 1; j <= n; j++) {
            if (text1.charAt(i - 1) == text2.charAt(j - 1))
                dp[i][j] = dp[i - 1][j - 1] + 1;
            else
                dp[i][j] = Math.max(dp[i - 1][j], dp[i][j - 1]);
        }
    }
    
    return dp[m][n];
}
```

### 4.1.5 状态压缩

我们也可以进行状态压缩，使得空间复杂度减少为 O(n)：
```java
public int longestCommonSubsequence(String text1, String text2) {
    // 我们只需要前一列和当前列的信息就可以更新当前行。
    // 结果实验，发现其实压缩行或压缩列都可以。

    // 保证列的长度大于等于行
    if (text1.length() < text2.length()) {
        String tmp = text1;
        text1 = text2;
        text2 = tmp;
    }

    final int m = text1.length(), n = text2.length();
    final int[] dp = new int[n + 1];

    for (int i = 1; i <= m; i++) {
        for (int j = 1, prevRow = 0, prevRowPrevCol; j <= n; j++) {
            // 因为可能用到 [i - 1][j - 1]、[i - 1][j]、[i][j - 1] 的值，为了不让值被覆盖，需要进行记录。
            // prevRow 保存 dp[i - 1][j] 的值；prevRowPrevCol 保存 dp[i - 1][j - 1] 的值

            prevRowPrevCol = prevRow;
            prevRow = dp[j];
            if (text1.charAt(i - 1) == text2.charAt(j - 1))
                dp[j] = prevRowPrevCol + 1;
            else
                dp[j] = Math.max(prevRow, dp[j - 1]);
        }
    }

    return dp[n];
}
```
需要注意的是，因为可能会用到左上、左边和上边的数据，为了防止数据被覆盖，我们需要跟踪并保存数据。

## 4.2 例 2：编辑距离

下面是题目：

![编辑距离][edit-distance]

为什么说这个问题难呢，因为显而易见，它就是难，让人手足无措，望而生畏。

为什么说它实用呢，因为前几天我就在日常生活中用到了这个算法。之前有一篇公众号文章由于疏忽，写错位了一段内容，
我决定修改这部分内容让逻辑通顺。但是公众号文章最多只能修改 20 个字，且只支持增、删、替换操作（跟编辑距离问题一模一样），
于是我就用算法求出了一个最优方案，只用了 16 步就完成了修改。

再比如高大上一点的应用，DNA 序列是由 A,G,C,T 组成的序列，可以类比成字符串。编辑距离可以衡量两个 DNA 序列的相似度，编辑距离越小，
说明这两段 DNA 越相似，说不定这俩 DNA 的主人是远古近亲啥的。

### 4.2.1 思路

编辑距离问题就是给我们两个字符串 `s1` 和 `s2`，只能用三种操作，让我们**把 `s1` 变成 `s2`**，求最少的操作数。需要明确的是，
不管是把 `s1` 变成 `s2` 还是反过来，结果都是一样的，所以后文就以 `s1` 变成 `s2` 举例。

![替换过程][edit-distance-procedure]

![步骤][edit-distance-static]

根据上面的 GIF，可以发现操作不只有三个，其实还有第四个操作，就是当两个字符相等时，什么都不要做（skip）。

还有一个很容易处理的情况，就是 `j` 走完 `s2` 时，如果 `i` 还没走完 `s1`，那么只能用删除操作把 `s1` 缩短为 `s2`。

类似的，如果 `i` 走完 `s1` 时 `j` 还没走完了 `s2`，那就只能用插入操作把 `s2` 剩下的字符全部插入 `s1`。等会会看到，
这两种情况就是算法的 **base case**。

### 4.2.2 代码详解

先梳理一下之前的思路：base case 是 `i` 走完 `s1` 或 `j` 走完 `s2`，可以直接返回另一个字符串剩下的长度。

对于每对儿字符 `s1[i]` 和 `s2[j]`，可以有四种操作：
```python
if s1[i] == s2[j]:
    啥都别做（skip）
    i, j 同时向前移动
else:
    三选一：
        插入（insert）
        删除（delete）
        替换（replace）
```

有这个框架，问题就已经解决了。读者也许会问，这个「三选一」到底该怎么选择呢？很简单，全试一遍，哪个操作最后得到的编辑距离最小，
就选谁。这里需要递归技巧，理解需要点技巧，先看下代码：
```java
public int minDistance(String word1, String word2) {
    IntBinaryOperator[] dp = new IntBinaryOperator[1];
    dp[0] = (i, j) -> {
        // base case
        if (i == -1)
            return j + 1;
        if (j == -1)
            return i + 1;

        if (word1.charAt(i) == word2.charAt(j))
            return dp[0].applyAsInt(i - 1, j - 1);            // 什么都不用做
        else
            return Math.min(dp[0].applyAsInt(i, j - 1),       // 插入
                    Math.min(dp[0].applyAsInt(i - 1, j),      // 删除
                            dp[0].applyAsInt(i - 1, j - 1)))  // 替换
                    + 1;                                      // 本次操作
    };

    return dp[0].applyAsInt(word1.length() - 1, word2.length() - 1);
}
```

我们这里 `dp(i, j)` 函数的定义是这样的：
```
返回 s1[0..i] 和 s2[0..j] 的最小编辑距离
```

记住这个定义之后，先来看这段代码：
```
if s1[i] == s2[j]:
    return dp(i - 1, j - 1)  # 啥都不做
# 解释：
# 本来就相等，不需要任何操作
# s1[0..i] 和 s2[0..j] 的最小编辑距离等于
# s1[0..i-1] 和 s2[0..j-1] 的最小编辑距离
# 也就是说 dp(i, j) 等于 dp(i-1, j-1)
```

如果 `s1[i] != s2[j]`，就要对三个操作递归了，稍微需要点思考：
```
dp(i, j - 1) + 1,    # 插入
# 解释：
# 我直接在 s1[i] 插入一个和 s2[j] 一样的字符
# 那么 s2[j] 就被匹配了，前移 j，继续跟 i 对比
# 别忘了操作数加一

dp(i - 1, j) + 1,    # 删除
# 解释：
# 我直接把 s[i] 这个字符删掉
# 前移 i，继续跟 j 对比
# 操作数加一

dp(i - 1, j - 1) + 1 # 替换
# 解释：
# 我直接把 s1[i] 替换成 s2[j]，这样它俩就匹配了
# 同时前移 i，j 继续对比
# 操作数加一
```

### 4.2.3 dp 数组的迭代解法

下面是 DP table 的解法：
```java
public int minDistance(String word1, String word2) {
    if (word1.length() == 0)
        return word2.length();
    if (word2.length() == 0)
        return word1.length();

    final int m = word1.length(), n = word2.length();
    // dp[i][j] 表示要使得 word1[0..i] == word2[0..j]，所需要的最小操作次数。
    final int[][] dp = new int[m + 1][n + 1];

    // base case
    for (int k = 1; k <= m; k++)
        dp[k][0] = k;
    for (int k = 1; k <= n; k++)
        dp[0][k] = k;

    for (int i = 1; i <= m; i++) {
        for (int j = 1; j <= n; j++) {
            if (word1.charAt(i - 1) == word2.charAt(j - 1))
                dp[i][j] = dp[i - 1][j - 1];            // 相等就不需要操作
            else
                dp[i][j] = Math.min(dp[i - 1][j - 1],   // 替换
                        Math.min(dp[i - 1][j],          // 删除
                                dp[i][j - 1]))          // 插入
                        + 1;                            // 加上这一次操作
        }
    }

    return dp[m][n];
}
```

### 4.2.4 状态压缩

下面是状态压缩后的代码：
```java
public int minDistance(String word1, String word2) {
    if (word1.length() == 0)
        return word2.length();
    if (word2.length() == 0)
        return word1.length();

    final int m = word1.length(), n = word2.length();
    final int[] dp = new int[n + 1];

    // 初始化 word1 长度为 0 的情况
    for (int k = 1; k <= n; k++)
        dp[k] = k;

    for (int i = 1; i <= m; i++) {
        // prevCol 保存当前行前一列的数据。
        // 我们压缩行，因此当前行前一列的数据需要保存，防止被覆盖
        int prevCol = i;
        // 之所以这里可以从左往右遍历，是因为我们已经记录了前一列的值了，不用担心覆盖
        for (int j = 1; j <= n; j++) {
            int cur;
            // dp[j - 1] 表示左上的数据： dp[i - 1][j - 1]
            // dp[j] 表示上一行的数据： dp[i - 1][j]
            if (word1.charAt(i - 1) == word2.charAt(j - 1))
                cur = dp[j - 1];
            else
                cur = Math.min(dp[j],       // 删除
                        Math.min(dp[j - 1], // 替换
                                prevCol))   // 插入
                        + 1;
            // 在这里覆盖当前行前一列的值
            dp[j - 1] = prevCol;
            prevCol = cur;
        }
        // 注意循环中只更新了 dp[j - 1]，因此不要忘了更新最后的 dp[n]
        dp[n] = prevCol;
    }

    return dp[n];
}
```

### 4.2.5 扩展延伸

一般来说，处理两个字符串的动态规划问题，都是按本文的思路处理，建立 DP table。为什么呢，因为易于找出状态转移的关系，
比如编辑距离的 DP table：

![DP table][edit-distance-table]

你可能还会问，这里只求出了最小的编辑距离，那具体的操作是什么？之前举的修改公众号文章的例子，只有一个最小编辑距离肯定不够，
还得知道具体怎么修改才行。这个其实很简单，代码稍加修改，给 `dp` 数组增加额外的信息即可：
```java
// int[][] dp;
Node[][] dp;

class Node {
    int val;
    int choice;
    // 0 代表啥都不做
    // 1 代表插入
    // 2 代表删除
    // 3 代表替换
}
```

我们的最终结果不是 `dp[m][n]` 吗，这里的 `val` 存着最小编辑距离，`choice` 存着最后一个操作，比如说是插入操作，
那么就可以左移一格：

![回溯操作][edit-distance-choice]

重复此过程，可以一步步回到起点 `dp[0][0]`，形成一条路径，按这条路径上的操作编辑对应索引的字符，就是最佳方案：

![完整操作路径][edit-distance-path]

## 4.3 例 3：最长递增子序列

前面的子序列问题都是两个子序列之间的操作。而有很多子序列问题是只关于一个子序列的。
所以我们就借助“最长递增子序列”这个问题来探讨一下这类问题的解决思路。
同时，这个问题也涉及到了一种设计动态规划的通用技巧：**数学归纳思想**。

题目如下：

![题目][lis-question]

最长递增子序列（Longest Increasing Subsequence，简写 LIS）是比较经典的一个问题，比较容易想到的是动态规划解法，
时间复杂度 O(N^2)，我们借这个问题来由浅入深讲解如何写动态规划。

比较难想到的是利用二分查找，时间复杂度是 O(N logN)，我们通过一种简单的纸牌游戏来辅助理解这种巧妙的解法。

### 4.3.1 动态规划解法：数学归纳法

**动态规划的核心设计思想是数学归纳法**。

相信大家对数学归纳法都不陌生，高中就学过，而且思路很简单。比如我们想证明一个数学结论，那么我们先假设这个结论在 `k < n` 时成立，
然后想办法证明 `k = n` 的时候此结论也成立。如果能够证明出来，那么就说明这个结论对于 `k` 等于任何数都成立。

类似的，我们设计动态规划算法，不是需要一个 `dp` 数组吗？我们可以假设 `dp[0...i−1]` 都已经被算出来了，然后问自己：
怎么通过这些结果算出 `dp[i]`?

直接拿最长递增子序列这个问题举例你就明白了。不过，首先要定义清楚 `dp` 数组的含义，即 `dp[i]` 的值到底代表着什么？
**我们的定义是这样的：`dp[i]` 表示以 `nums[i]` 这个数「结尾」的最长递增子序列的长度**。

举个例子，算法演进的过程是这样的：

![算法演进过程][lis-procedure]

根据这个定义，我们的最终结果（子序列的最大长度）应该是 `dp` 数组中的最大值。
```java
int res = 0;
for (int i = 0; i < dp.length; i++) {
    res = Math.max(res, dp[i]);
}
return res;
```
**这里注意到，`dp` 数组的最后一个结果不一定就是答案**。

读者也许会问，刚才这个过程中每个 `dp[i]` 的结果是我们肉眼看出来的，我们应该怎么设计算法逻辑来正确计算每个 `dp[i]` 呢？
这就是动态规划的重头戏了，要思考如何进行状态转移，这里就可以使用数学归纳的思想：
我们已经知道了 `dp[0...4]` 的所有结果，我们如何通过这些已知结果推出 `dp[5]` 呢？

![数学归纳法][lis-induction]

根据刚才我们对 `dp` 数组的定义，现在想求 `dp[5]` 的值，也就是想求以 `nums[5]` 为结尾的最长递增子序列。
`nums[5] = 3`，既然是递增子序列，我们只要找到前面那些结尾比 3 小的子序列，然后把 3 接到最后，就可以形成一个新的递增子序列，
而且这个新的子序列长度加一。

当然，可能形成很多种新的子序列，但是我们只要最长的，把最长子序列的长度作为 `dp[5]` 的值即可。

到这里，这道算法题我们就基本做完了。读者也许会问，我们刚才只是算了 `dp[5]` 呀，`dp[4]`, `dp[3]` 这些怎么算呢？
类似数学归纳法，你已经可以通过 `dp[0...4]` 算出 `dp[5]` 了，那么任意 `dp[i]` 你肯定都可以算出来：
```java
public int lengthOfLIS(int[] nums) {
    // dp[i] 表示以 nums[i] 「结尾」的最长递增子序列的长度
    int[] dp = new int[nums.length];

    for (int i = 0; i < nums.length; i++) {
        dp[i] = 1;
        // 将 nums[i] 接到前面每个子序列试试看，从中选出最长的那个
        for (int j = 0; j < i; j++) {
            if (nums[i] > nums[j])
                dp[i] = Math.max(dp[i], dp[j] + 1);
        }
    }

    int max = dp[0];
    for (int i = 1; i < dp.length; i++)
        max = Math.max(dp[i], max);

    return max;
}
```

至此，这道题就解决了，时间复杂度 O(N^2)。总结一下动态规划的设计流程：
1. 首先明确 `dp` 数组所存数据的含义。这步很重要，如果不得当或者不够清晰，会阻碍之后的步骤。
2. 然后根据 `dp` 数组的定义，运用数学归纳法的思想，假设 `dp[0...i−1]` 都已知，想办法求出 `dp[i]`，一旦这一步完成，
整个题目基本就解决了。
3. 但如果无法完成这一步，很可能就是 `dp` 数组的定义不够恰当，需要重新定义 `dp` 数组的含义；或者可能是 `dp` 数组存储的信息还不够，
不足以推出下一步的答案，需要把 `dp` 数组扩大成二维数组甚至三维数组。

### 4.3.2 二分查找解法

其实最长递增子序列和一种叫做 patience game 的纸牌游戏有关，甚至有一种排序方法就叫做 patience sorting（耐心排序）。

为了简单起见，后文跳过所有数学证明，通过一个简化的例子来理解一下思路。
首先，给你一排扑克牌，我们像遍历数组那样从左到右一张一张处理这些扑克牌，最终要把这些牌分成若干堆。

![牌堆][lis-bs]

处理这些扑克牌要遵循以下规则：
 - 只能把点数小的牌压到点数比它大的牌上。
 - 如果当前牌点数较大没有可以放置的堆，则新建一个堆，把这张牌放进去。
 - 如果当前牌有多个堆可供选择，则选择最左边的堆放置。

比如说上述的扑克牌最终会被分成这样 5 堆（我们认为 A 的值是最大的，而不是 1）：

![牌堆][lis-poker]

为什么遇到多个可选择堆的时候要放到最左边的堆上呢？因为这样可以保证牌堆顶的牌有序（2, 4, 7, 8, Q），证明略。

按照上述规则执行，可以算出最长递增子序列，牌的堆数就是我们想求的最长递增子序列的长度，证明略。

![最终结果][lis-result]

我们只要把处理扑克牌的过程编程写出来即可。每次处理一张扑克牌不是要找一个合适的牌堆顶来放吗，牌堆顶的牌不是有序吗，
这就能用到[二分查找][bs]了：用二分查找来搜索当前牌应放置的位置。

代码如下所示：
```java
public int lengthOfLIS(int[] nums) {
    // 每堆牌最上面的牌
    int[] top = new int[nums.length];
    // 排队初始化为 0
    int piles = 0;

    for (int i = 0; i < nums.length; i++) {
        // 二分查找搜索匹配的最左边牌堆
        int lo = 0, hi = piles;
        while (lo < hi) {
            int mid = (lo + hi) >>> 1;
            if (nums[i] > top[mid])
                lo = mid + 1;
            else
                hi = mid;
        }
        // 没找到合适的牌堆，新建一堆
        if (lo == piles)
            piles++;
        // 将牌放到牌堆上面
        top[lo] = nums[i];
    }

    // 牌堆数就是 LIS 长度
    return piles;
}
```

## 4.4 例 4：信封嵌套

很多算法问题都需要排序技巧，其难点不在于排序本身，而是需要巧妙地排序进行预处理，将算法问题进行转换，为之后的操作打下基础。

信封嵌套问题就需要先按特定的规则排序，之后就转换为一个最长递增子序列问题，可以用例 3 的技巧来解决了。

### 4.4.1 题目概述

![信封嵌套][nest-question]

这道题目其实是最长递增子序列（Longes Increasing Subsequence，简写为 LIS）的一个变种，因为很显然，每次合法的嵌套是大的套小的，
相当于找一个最长递增的子序列，其长度就是最多能嵌套的信封个数。

但是难点在于，标准的 LIS 算法只能在数组中寻找最长子序列，而我们的信封是由 `(w,h)` 这样的二维数对形式表示的，如何把 LIS 算法运用过来呢？

### 4.4.2 解法

这道题的解法是比较巧妙的：
先对宽度 `w` 进行升序排序，如果遇到 `w` 相同的情况，则按照高度 `h` 降序排序。之后把所有的 `h` 作为一个数组，
在这个数组上计算 LIS 的长度就是答案。

![排序][nest-sort]

然后在 `h` 上寻找最长递增子序列：

![LIS][nest-lis]

这个解法的关键在于，对于宽度 `w` 相同的数对，要对其高度 `h` 进行降序排序。
**因为两个宽度相同的信封不能相互包含的，而逆序排序保证在 `w` 相同的数对中最多只选取一个计入 LIS**。

下面看代码：
```java
public int maxEnvelopes(int[][] envelopes) {
    // 将信封先按照宽度升序排序，再按照高度降序排序。
    // 之所以按照高度降序排序，是因为相同宽度的信封是不能包含的。
    Arrays.sort(envelopes, (ei, ej) -> {
        int cmp;
        return (cmp = Integer.compare(ei[0], ej[0])) != 0
                ? cmp
                : -Integer.compare(ei[1], ej[1]);
    });

    // 最后求高度的最长递增子序列
    return lengthOfLIS(envelopes);
}

private int lengthOfLIS(int[][] nums) {
    int[] top = new int[nums.length];
    int piles = 0;

    for (int i = 0; i < nums.length; i++) {
        int lo = 0, hi = piles;
        while (lo < hi) {
            int mid = (lo + hi) >>> 1;
            if (nums[i][1] > top[mid])
                lo = mid + 1;
            else
                hi = mid;
        }
        if (lo == piles)
            piles++;
        top[lo] = nums[i][1];
    }

    return piles;
}
```

### 4.4.3 拓展

其实这种问题还可以拓展到三维，比如说现在不是让你嵌套信封，而是嵌套箱子，每个箱子有长宽高三个维度，
请你算算最多能嵌套几个箱子？

我们可能会这样想，先把前两个维度（长和宽）按信封嵌套的思路求一个嵌套序列，最后在这个序列的第三个维度（高度）找一下 LIS，
应该能算出答案。

实际上，这个思路是错误的。这类问题叫做**偏序问题**，上升到三维会使难度巨幅提升，需要借助一种高级数据结构**树状数组**，
有兴趣的读者可以自行搜索了解一下。

## 4.5 例 5：最长回文子序列

![最长回文子序列][lps-question]

这个题目有两种思路，时间复杂度大致相同。这也印证了不同的状态定义会导致不同的解题思路。

### 4.5.1 第一种方法

这种方法是利用了这样的性质：字符串 `s` 和它的反序字符串 `rs` 的最长公共子序列长度也就是最长回文子序列的长度。

这样的话，解题思路就和「最长公共子序列」几乎一样：
```java
public int longestPalindromeSubseq(String s) {
    final int n = s.length();
    // 定义 dp[i][j] 是 s 中前 i 个字符和 rs（s 的相反串）中相等的最长子序列长度。
    // 这样问题就转化为了“最长公共子序列”问题。
    // 注意下面是压缩了行的 dp 数组
    final int[] dp = new int[n + 1];

    for (int i = 1; i <= n; i++) {
        // prevCol 保存当前行前一列的数据。
        int preCol = 0;
        for (int j = 1; j <= n; j++) {
            int cur;
            if (s.charAt(i - 1) == s.charAt(n - j))
                cur = dp[j - 1] + 1;
            else
                cur = Math.max(preCol, dp[j]);
            dp[j - 1] = preCol;
            preCol = cur;
        }
        dp[n] = preCol;
    }

    return dp[n];
}
```

### 4.5.2 第二种方法

这个方法对 `dp` 数组的定义是：在子串 `s[i..j]` 中，最长回文子序列的长度为 `dp[i][j]`。

具体来说，如果我们想求 `dp[i][j]`，假设你知道了子问题 `dp[i+1][j-1]` 的结果（`s[i+1..j-1]` 中最长回文子序列的长度），
你是否能想办法算出 `dp[i][j]` 的值（`s[i..j]` 中，最长回文子序列的长度）呢？可以！这取决于 `s[i]` 和 `s[j]` 的字符。

**如果它俩相等**，那么它俩加上 `s[i+1..j-1]` 中的最长回文子序列就是 `s[i..j]` 的最长回文子序列：

![相等][lps-eq]

**如果它俩不相等**，说明它俩不可能同时出现在 `s[i..j]` 的最长回文子序列中，那么把它俩分别加入 `s[i+1..j-1]` 中，
看看哪个子串产生的回文子序列更长即可：

![不相等][lps-ne]

以上两种情况写成代码就是这样：
```java
if (s[i] == s[j])
    // 它俩一定在最长回文子序列中
    dp[i][j] = dp[i + 1][j - 1] + 2;
else
    // s[i+1..j] 和 s[i..j-1] 谁的回文子序列更长？
    dp[i][j] = max(dp[i + 1][j], dp[i][j - 1]);
```

至此，状态转移方程就写出来了，根据 `dp` 数组的定义，我们要求的就是 `dp[0][n - 1]`，也就是整个 `s` 的最长回文子序列的长度。

首先明确一下 base case，如果只有一个字符，显然最长回文子序列长度是 1，也就是 `dp[i][j] = 1,(i == j)`。
因为 `i` 肯定小于等于 `j`，所以对于那些 `i > j` 的位置，根本不存在什么子序列，应该初始化为 0。

另外，看看刚才写的状态转移方程，想求 `dp[i][j]` 需要知道 `dp[i+1][j-1]`，`dp[i+1][j]`，`dp[i][j-1]` 这三个位置；
再看看我们确定的 base case，填入 `dp` 数组之后是这样：

![DP table][lps-table]

为了保证每次计算 `dp[i][j]`，左、下、左下三个方向的位置已经被计算出来，只能斜着遍历或者反着遍历：

![遍历顺序][lps-scan]

我选择反着遍历，代码如下：
```java
public int longestPalindromeSubseq(String s) {
    int n = s.length();
    // 在子串 s[i..j] 中，最长回文子序列的长度为 dp[i][j]
    int[][] dp = new int[n][n];
    // base case
    for (int i = 0; i < n; i++)
        dp[i][i] = 1;

    // 反着遍历保证正确的状态转移
    for (int i = n - 1; i >= 0; i--) {
        for (int j = i + 1; j < n; j++) {
            // 状态转移方程
            if (s.charAt(i) == s.charAt(j))
                dp[i][j] = dp[i + 1][j - 1] + 2;
            else
                dp[i][j] = Math.max(dp[i + 1][j], dp[i][j - 1]);
        }
    }

    // 整个 s 的最长回文子串长度
    return dp[0][n - 1];
}
```

可以看到，这种方法定义的 `dp` 数组遍历方向也不一样。

### 4.5.3 第二种方法的状态压缩——斜向遍历的压缩

你看我们对 `dp[i][j]` 的更新，其实只依赖于 `dp[i+1][j-1], dp[i][j-1], dp[i+1][j]` 这三个状态：

![依赖状态][lps-state]

**状态压缩的核心思路就是，将二维数组「投影」到一维数组**：

![投影][lps-projection]

思路很直观，但是也有一个明显的问题，图中 `dp[i][j-1]` 和 `dp[i+1][j-1]` 这两个状态处在同一列，而一维数组中只能容下一个，
那么当我计算 `dp[i][j]` 时，他俩必然有一个会被另一个覆盖掉，怎么办？

想把二维 `dp` 数组压缩成一维，一般来说是把第一个维度，也就是 `i` 这个维度去掉，只剩下 `j` 这个维度。
压缩后的一维 `dp` 数组就是之前二维 `dp` 数组的 `dp[i][..]` 那一行。
我们先将上述代码进行改造，直接无脑去掉 `i` 这个维度，把 `dp` 数组变成一维：
```java
for (int i = n - 1; i >= 0; i--) {
    for (int j = i + 1; j < n; j++) {
        if (s.charAt(i) == s.charAt(j))
            dp[j] = dp[j - 1] + 2;
        else
            dp[j] = Math.max(dp[j], dp[j - 1]);
    }
}
```

在代码中注释的位置，将要进行状态转移，更新 `dp[j]`，那么我们要来思考两个问题：
1. 在对 `dp[j]` 赋新值之前，`dp[j]` 对应着二维 `dp` 数组中的什么位置？
2. `dp[j-1]` 对应着二维 `dp` 数组中的什么位置？

对于问题 1，在对 `dp[j]` 赋新值之前，`dp[j]` 的值就是外层 `for` 循环上一次迭代算出来的值，
也就是对应二维 `dp` 数组中 `dp[i+1][j]` 的位置。

对于问题 2，`dp[j-1]` 的值就是内层 `for` 循环上一次迭代算出来的值，也就是对应二维 `dp` 数组中 `dp[i][j-1]` 的位置。

那么问题已经解决了一大半了，只剩下二维 `dp` 数组中的 `dp[i+1][j-1]` 这个状态我们不能直接从一维 `dp` 数组中得到：
```java
for (int i = n - 2; i >= 0; i--) {
    for (int j = i + 1; j < n; j++) {
        if (s[i] == s[j])
            // dp[i][j] = dp[i+1][j-1] + 2;
            dp[j] = ?? + 2;
        else
            // dp[i][j] = max(dp[i+1][j], dp[i][j-1]);
            dp[j] = max(dp[j], dp[j - 1]);
    }
}
```

那么如果我们想得到 `dp[i+1][j-1]`，就必须在它被覆盖之前用一个临时变量 `temp` 把它存起来，
并把这个变量的值保留到计算 `dp[i][j]` 的时候。为了达到这个目的，结合上图，我们可以这样写代码：
```java
for (int i = n - 2; i >= 0; i--) {
    // 存储 dp[i+1][j-1] 的变量
    int pre = 0;
    for (int j = i + 1; j < n; j++) {
        int temp = dp[j];
        if (s[i] == s[j])
            // dp[i][j] = dp[i+1][j-1] + 2;
            dp[j] = pre + 2;
        else
            dp[j] = max(dp[j], dp[j - 1]);
        // 到下一轮循环，pre 就是 dp[i+1][j-1] 了
        pre = temp;
    }
}
```

那么现在我们成功对状态转移方程进行了降维打击，算是最硬的的骨头啃掉了，但注意到我们还有 base case 要处理呀：
```java
// base case
for (int i = 0; i < n; i++)
    dp[i][i] = 1;
```

如何把 base case 也打成一维呢？很简单，**记住，状态压缩就是投影**，我们把 base case 投影到一维看看：

![base case][lps-base]

二维 `dp` 数组中的 base case 全都落入了一维 `dp` 数组，不存在冲突和覆盖，所以说我们直接这样写代码就行了：
```java
for (int i = 0; i < n; i++)
    dp[i] = 1;
```

至此，我们把 base case 和状态转移方程都进行了降维，实际上已经写出完整代码了：
```java
int longestPalindromeSubseq(String s) {
    int n = s.length();
    // base case：一维 dp 数组全部初始化为 1
    final int[] dp = new int[n];
    for (int i = 0; i < n; i++)
        dp[i] = 1;

    for (int i = n - 2; i >= 0; i--) {
        int pre = 0;
        for (int j = i + 1; j < n; j++) {
            int temp = dp[j];
            // 状态转移方程
            if (s.charAt(i) == s.charAt(j))
                dp[j] = pre + 2;
            else
                dp[j] = Math.max(dp[j], dp[j - 1]);
            pre = temp;
        }
    }

    return dp[n - 1];
}
```

# 5. dp 数组的遍历方向

我相信读者做动态规划问题时，肯定会对 `dp` 数组的遍历顺序有些头疼。我们拿二维 `dp` 数组来举例，有时候我们是正向遍历：
```java
int[][] dp = new int[m][n];
for (int i = 0; i < m; i++)
    for (int j = 0; j < n; j++)
        // 计算 dp[i][j]
```

有时候我们反向遍历：
```java
for (int i = m - 1; i >= 0; i--)
    for (int j = n - 1; j >= 0; j--)
        // 计算 dp[i][j]
```

有时候可能会斜向遍历：
```java
// 正斜遍历数组
for (int l = 2; l <= n; l++) {
    for (int i = 0; i <= n - l; i++) {
        int j = l + i - 1;
        // 计算 dp[i][j]
    }
}
```

甚至更让人迷惑的是，有时候发现正向反向遍历都可以得到正确答案。那么，如果仔细观察的话可以发现其中的原因的。你只要把住两点就行了：
1. **遍历的过程中，所需的状态必须是已经计算出来的**。
2. **遍历的终点必须是存储结果的那个位置**。

比如编辑距离这个经典的问题，我们通过对 `dp` 数组的定义，确定了 base case 是 `dp[..][0]` 和 `dp[0][..]`，
最终答案是 `dp[m][n]`；而且我们通过状态转移方程知道 `dp[i][j]` 需要从 `dp[i-1][j]`,`dp[i][j-1]`,`dp[i-1][j-1]` 转移而来，
如下图：

![编辑距离遍历顺序][scan-edit]

那么，参考刚才说的两条原则，你该怎么遍历 `dp` 数组？肯定是正向遍历：

```java
for (int i = 1; i < m; i++)
    for (int j = 1; j < n; j++)
        // 通过 dp[i-1][j], dp[i][j - 1], dp[i-1][j-1]
        // 计算 dp[i][j]
```

因为，这样每一步迭代的左边、上边、左上边的位置都是 base case 或者之前计算过的，而且最终结束在我们想要的答案 `dp[m][n]`。

再举一例，回文子序列问题，我们通过过对 `dp` 数组的定义，确定了 base case 处在中间的对角线，
`dp[i][j]` 需要从 `dp[i+1][j]`,`dp[i][j-1]`,`dp[i+1][j-1]` 转移而来，想要求的最终答案是 `dp[0][n-1]`。
这种情况根据刚才的两个原则，就可以有两种正确的遍历方式：

![回文子序列遍历顺序][lps-scan]

要么从左至右斜着遍历，要么从下向上从左到右遍历，这样才能保证每次 `dp[i][j]` 的左边、下边、左下边已经计算完毕，
最终得到正确结果。

现在，你应该理解了这两个原则，主要就是看 base case 和最终结果的存储位置，保证遍历过程中使用的数据都是计算完毕的就行，
有时候确实存在多种方法可以得到正确答案，可根据个人口味自行选择。

# 6. 背包问题

## 6.1 0-1 背包问题

今天就来说一下背包问题吧，就讨论最常说的 0-1 背包问题，简单描述一下吧：
给你一个可装载重量为 `W` 的背包和 `N` 个物品，每个物品有重量和价值两个属性。其中第 `i` 个物品的重量为 `wt[i]`，
价值为 `val[i]`，现在让你用这个背包装物品，最多能装的价值是多少？

举个简单的例子，输入如下：
```
N = 3, W = 4
wt = [2, 1, 3]
val = [4, 2, 3]
```

算法返回 6，选择前两件物品装进背包，总重量 3 小于 `W`，可以获得最大价值 6。

题目就是这么简单，一个典型的动态规划问题。这个题目中的物品不可以分割，要么装进包里，要么不装，不能说切成两块装一半。
这也许就是 0-1 背包这个名词的来历。解决这个问题没有什么排序之类巧妙的方法，只能穷举所有可能，
根据我们动态规划中的套路，直接走流程就行了。

### 6.1.1 解题思路

 - **第一步要明确两点，「状态」和「选择」**。

先说状态，如何才能描述一个问题局面？只要给定几个可选物品和一个背包的容量限制，就形成了一个背包问题，对不对？
**所以状态有两个，就是「背包的容量」和「可选择的物品」**。

 - **第二步要明确 `dp` 数组的定义**。

首先看看刚才找到的「状态」，有两个，也就是说我们需要一个二维 `dp` 数组，一维表示可选择的物品，一维表示背包的容量。
**`dp[i][w]` 的定义如下：对于前 `i` 个物品，当前背包的容量为 `w`，这种情况下可以装的最大价值是 `dp[i][w]`**。

比如说，如果 `dp[3][5] = 6`，其含义为：对于给定的一系列物品中，若只对前 3 个物品进行选择，当背包容量为 5 时，
最多可以装下的价值为 6。

**根据这个定义，我们想求的最终答案就是 `dp[N][W]`。base case 就是 `dp[0][..] = dp[..][0] = 0`**，
因为没有物品或者背包没有空间的时候，能装的最大价值就是 0。

细化上面的框架：
```java
int dp[N+1][W+1]
dp[0][..] = 0
dp[..][0] = 0

for i in [1..N]:
    for w in [1..W]:
        dp[i][w] = max(
            把物品 i 装进背包,
            不把物品 i 装进背包
        )
return dp[N][W]
```

 - **第三步，根据「选择」，思考状态转移的逻辑**。

简单说就是，上面伪码中「把物品 `i` 装进背包」和「不把物品 `i` 装进背包」怎么用代码体现出来呢？
这一步要结合对 `dp` 数组的定义和我们的算法逻辑来分析：
1. 如果你没有把这第 `i` 个物品装入背包，那么很显然，最大价值 `dp[i][w]` 应该等于 `dp[i-1][w]`。你不装嘛，那就继承之前的结果。
2. 如果你把这第 `i` 个物品装入了背包，那么 `dp[i][w]` 应该等于 `dp[i-1][w-wt[i-1]] + val[i-1]`。
    1. 首先，由于 `i` 是从 1 开始的，所以对 `val` 和 `wt` 的取值是 `i-1`。
    2. 而 `dp[i-1][w-wt[i-1]]` 也很好理解：你如果想装第 `i` 个物品，你怎么计算这时候的最大价值？
    换句话说，在装第 `i` 个物品的前提下，背包能装的最大价值是多少？
    3. 显然，你应该寻求剩余重量 `w-wt[i-1]` 限制下能装的最大价值，加上第 `i` 个物品的价值 `val[i-1]`，
    这就是装第 `i` 个物品的前提下，背包可以装的最大价值。

### 6.1.2 具体代码

综上就是两种选择，我们都已经分析完毕，也就是写出来了状态转移方程，可以进一步细化代码：
```java
int knapsack(int W, int N, int[] wt, int[] val) {
    // base case 已初始化
    int[][] dp = new int[N + 1][W + 1];
    for (int i = 1; i <= N; i++) {
        for (int w = 1; w <= W; w++) {
            if (w - wt[i-1] < 0) {
                // 当前背包容量装不下，只能选择不装入背包
                dp[i][w] = dp[i - 1][w];
            } else {
                // 装入或者不装入背包，择优
                dp[i][w] = Math.max(dp[i - 1][w - wt[i-1]] + val[i-1], 
                               dp[i - 1][w]);
            }
        }
    }

    return dp[N][W];
}
```

现在你看这个解法代码，是不是感觉非常简单，就是把我们刚才分析的思路原封不动翻译了一下而已。
所以说，明确了动态规划的套路，思路就显得行云流水，非常自然就出答案了。

0-1 背包问题的一个例子就是 2.2 节的凑硬币问题。

## 6.2 子集背包问题

先看一下题目：

![分割等和子集][bag-subset]

对于这个问题，看起来和背包没有任何关系，为什么说它是背包问题呢？因为我们可以先对集合求和，得出 `sum`，把问题转化为背包问题：

**给一个可装载重量为 `sum/2` 的背包和 `N` 个物品，每个物品的重量为 `nums[i]`。现在让你装物品，是否存在一种装法，
能够恰好将背包装满**？你看，这就是背包问题的模型，甚至比我们之前的经典背包问题还要简单一些，下面我们就直接转换成背包问题，
开始套前文讲过的背包问题框架即可。

### 6.2.1 解法框架

下面就是代码：
```java
public boolean canPartition(int[] nums) {
    int sum = 0;
    for (int num : nums)
        sum += num;
    if ((sum & 1) != 0)
        return false;

    // 如果能够能够装满背包（物品总容量的一半），则表示有解
    int n = nums.length, bagCap = sum >>> 1;
    // dp[i][w] 表示尝试将前 i 个数字装入容量为 w 的背包的所能达到的最大值
    int[][] dp = new int[n + 1][bagCap + 1];
    for (int i = 1; i <= n; i++) {
        for (int w = 1; w <= bagCap; w++) {
            // 背包容量小于数字的值，只能舍弃，沿用上一次的结果
            if (w < nums[i - 1])
                dp[i][w] = dp[i - 1][w];
            else
                // 尝试将数字装入背包，比较和不装的值哪个大
                dp[i][w] = Math.max(dp[i - 1][w], dp[i - 1][w - nums[i - 1]] + nums[i - 1]);
        }
    }

    // 装满了背包表示有解
    return dp[n][bagCap] == bagCap;
}
```

我们可以进行状态压缩：
```java
public boolean canPartition(int[] nums) {
    int sum = 0;
    for (int num : nums)
        sum += num;
    if ((sum & 1) != 0)
        return false;

    int n = nums.length, bagCap = sum >>> 1;
    // 压缩行
    int[] dp = new int[bagCap + 1];
    for (int i = 0; i < n; i++) {
        // 注意要倒着进行，因为右边的状态依赖于左边的状态
        for (int w = bagCap; w >= 1; w--) {
            if (w >= nums[i])
                dp[w] = Math.max(dp[w], dp[w - nums[i]] + nums[i]);
        }
    }

    return dp[bagCap] == bagCap;
}
```

### 6.2.2 思路优化

我们最后想求的是「能否装满一半」，因此我们可以如此定义 `dp` 数组：`dp[i][j] = x` 表示，对于前 `i` 个物品，
当前背包的容量为 `j` 时，若 `x` 为 `true`，则说明可以恰好将背包装满，若 `x` 为 `false`，则说明不能恰好将背包装满。

比如说，如果 `dp[4][9] = true`，其含义为：对于容量为 9 的背包，若只是用前 4 个物品，可以有一种方法把背包恰好装满。

根据这个定义，我们想求的最终答案就是 `dp[N][sum/2]`，base case 就是 `dp[..][0] = true` 和 `dp[0][..] = false`，
因为背包没有空间的时候，就相当于装满了，而当没有物品可选择的时候，肯定没办法装满背包。

回想刚才的dp数组含义，可以根据「选择」对 `dp[i][j]` 得到以下状态转移：
 - 如果不把 `nums[i]` 算入子集，或者说你不把这第 `i` 个物品装入背包，那么是否能够恰好装满背包，
 取决于上一个状态 `dp[i-1][j]`，继承之前的结果。
 - 如果把 `nums[i]` 算入子集，或者说你把这第 `i` 个物品装入了背包，那么是否能够恰好装满背包，
 取决于状态 `dp[i - 1][j-nums[i-1]]`。

于是我们可以写出更精确的代码：
```java
public boolean betterMethod(int[] nums) {
    int sum = 0;
    for (int num : nums)
        sum += num;
    if ((sum & 1) != 0)
        return false;

    int n = nums.length, bagCap = sum >>> 1;
    boolean[] dp = new boolean[bagCap + 1];
    dp[0] = true;
    for (int i = 0; i < n; i++) {
        // 注意反向遍历，因为右边的状态依赖于左边的状态
        for (int w = bagCap; w >= 1; w--) {
            if (w >= nums[i])
                // 装入或不装入背包
                dp[w] = dp[w] || dp[w - nums[i]];
        }
    }

    return dp[bagCap];
}
```

## 6.3 完全背包问题

本次主题聊的是 LeetCode 第 518 题 Coin Change 2，题目如下：

![Coin Change II][bag-coin]

至于 Coin Change 1，在 2.2 节中讲过。

我们可以把这个问题转化为背包问题的描述形式：
有一个背包，最大容量为 `amount`，有一系列物品 `coins`，每个物品的重量为 `coins[i]`，每个物品的数量无限。
请问有多少种方法，能够把背包恰好装满？

这个问题和我们前面讲过的两个背包问题，有一个最大的区别就是，**每个物品的数量是无限的，这也就是传说中的「完全背包问题」**，
没啥高大上的，无非就是状态转移方程有一点变化而已。

### 6.3.1 解题思路

**第一步要明确两点，「状态」和「选择」**。

这部分都是背包问题的老套路了，我还是啰嗦一下吧：
 - 状态有两个，就是「背包的容量」和「可选择的物品」
 - 选择就是「装进背包」或者「不装进背包」。

**第二步要明确 `dp` 数组的定义**。

首先看看刚才找到的「状态」，有两个，也就是说我们需要一个二维 `dp` 数组。`dp[i][j]` 的定义如下：
若只使用前 `i` 个物品，当背包容量为 `j` 时，有 `dp[i][j]` 种方法可以装满背包。

换句话说，翻译回我们题目的意思就是：若只使用 `coins` 中的前 `i` 个硬币的面值，若想凑出金额 `j`，
有 `dp[i][j]` 种凑法。

经过以上的定义，可以得到：base case 为 `dp[0][..] = 0`，`dp[..][0] = 1`。因为如果不使用任何硬币面值，
就无法凑出任何金额；如果凑出的目标金额为 0，那么“无为而治”就是唯一的一种凑法。
我们最终想得到的答案就是 `dp[N][amount]`，其中 `N` 为 `coins` 数组的大小。

**第三步，根据「选择」，思考状态转移的逻辑**。

注意，我们这个问题的特殊点在于物品的数量是无限的，所以这里和之前写的背包问题文章有所不同。
 - 如果你不把这第 `i` 个物品装入背包，也就是说你不使用 `coins[i]` 这个面值的硬币，
 那么凑出面额 `j` 的方法数 `dp[i][j]` 应该等于 `dp[i-1][j]`，继承之前的结果。
 - 如果你把这第 `i` 个物品装入了背包，也就是说你使用 `coins[i]` 这个面值的硬币，
 那么 `dp[i][j]` 应该等于 `dp[i][j-coins[i-1]]`（注意等于的是 `dp[i][..]`，而不是 `dp[i-1][..]`）。

综上就是两种选择，而我们想求的 `dp[i][j]` 是「共有多少种凑法」，所以 `dp[i][j]` 的值应该是以上两种选择的结果之和：
`dp[i][j] = dp[i-1][j] + dp[i][j-coins[i-1]]`。

你可能有疑问，为什么只选了一次 `coins[i-1]` 呢？不应该选择多次直到大于 `j` 吗？
可以这样理解，`dp[i][j-coins[i-1]]` 是用前 `i` 个硬币凑出了金额 `j-coins[i-1]`，
再加上一个 `coins[i - 1]` 也就等于 `j`，利用数学归纳法很容易理解。

这还可以通过数学方法推导出公式（下面的公式假设 `coins` 从 1 开始，简化公式）：

![公式（1）][bag-coin-e1]

这里 `j - k * coins[i] >= 0`。将 `j` 用 `coins[i]` 替换，得：

![公式（2）][bag-coin-e2]

这里 `j - coins[i] - k * coins[i] >= 0`。整理得：

![公式（3）][bag-coin-e3]

这里 `j - k * coins[i] >= 0`。

![公式（4）][bag-coin-e4]

**所以其实每一行单元的值的填写只要看它的左边的值**。如果没有左边，它至少是上一行单元格的值。

### 6.3.2 代码

最后写出来的 Java 代码如下所示：
```java
public int change(int amount, int[] coins) {
    if (amount == 0)
        return 1;

    final int n = coins.length;
    // dp[i][a] 表示使用前 i 个硬币凑出 a 的方法次数
    final int[][] dp = new int[n + 1][amount + 1];
    // amount 等于 0，则可以不使用硬币就凑出，因此有一种方法
    for (int i = 0; i <= n; i++)
        dp[i][0] = 1;

    for (int i = 1; i <= n; i++) {
        for (int a = 1; a <= amount; a++) {
            // 继承上一次的结果
            dp[i][a] += dp[i - 1][a];
            // 硬币面额小于容量，尝试将其添加进去。
            if (coins[i - 1] <= a)
                dp[i][a] += dp[i][a - coins[i - 1]];
        }
    }

    return dp[n][amount];
}
```

### 6.3.3 状态压缩

由状态转移方程 (5) 知道，当前状态值参考了当前行前面的值，因此将空间优化到一维 `dp` 的时候，正序遍历是合理的。
你也可以这样想：正序会重复选择物品，相当于物品数量无限，倒序不会重复拿物品，相当于每个物品只有一个。

代码如下：
```java
public int compressMethod(int amount, int[] coins) {
    if (amount == 0)
        return 1;

    final int n = coins.length;
    // 压缩行
    final int[] dp = new int[amount + 1];
    dp[0] = 1;

    for (int i = 1; i <= n; i++) {
        for (int a = 1; a <= amount; a++) {
            if (coins[i - 1] <= a)
                dp[a] += dp[a - coins[i - 1]];
        }
    }

    return dp[amount];
}
```

## 6.4 排列背包问题——子问题定义

在前面的背包问题中，列举的所有可能都不考虑顺序，**属于「组合问题」**。而有时候题目还会要求我们考虑顺序，
这种问题就**属于「排列问题」**。

### 6.4.1 爬楼梯

我们来看一个简单的例子，爬楼梯问题：

![爬楼梯][bag-stair]

**这道题目子问题是，`problem(i) = sub(i-1) + sub(i-2)`**，即求解第 `i` 阶楼梯等于求解第 `i-1` 阶楼梯和第 `i-2` 阶楼梯之和。
通过这个子问题定义我们很快便能够写出代码：
```java
public int climbStairs(int n) {
    int[] dp = new int[n + 1];
    dp[0] = dp[1] = 1;

    for (int i = 2; i <= n; i++) {
        dp[i] = dp[i - 1] + dp[i - 2];
    }

    return dp[n];
}
```

经过状态压缩，可以得到和斐波那契数数列类似的方法：
```java
public int climbStairs(int n) {
    int i = 1, j = 1;

    for (int k = 2; k <= n; k++) {
        int next = i + j;
        i = j;
        j = next;
    }

    return j;
}
```

### 6.4.2 拓展

原问题太简单了，定义了子问题很快就能出结果。如果我们把问题泛化，不再是固定的 1，2，而是任意给定台阶数，例如 1,2,5 呢？
我们只需要修改我们的 `dp` 方程 `dp[i] = dp[i-1] + dp[i-2] + dp[i-5]`, 也就是 `dp[i] = dp[i] + dp[i-j] ,j =1,2,5`。

在原来的基础上，我们的代码可以做这样的修改：
```java
public int climbStairs(int n) {
    int[] dp = new int[n + 1], steps = {1, 2, 5};
    dp[0] = 1;
    
    for (int i = 1; i <= n; i++){
        for (int j = 0; j < steps.length; j++){
            int step = steps[j];
            if (i < step) continue; // 台阶少于跨越的步数
            dp[i] += dp[i - step];
        }
    }

    return dp[n];
}
```
后续修改 `steps` 数组，就实现了原来问题的泛化。

我们能不能交换内外的循环呢？也就是下面的代码：
```java
for (int j = 0; j < steps.length; j++){
    int step = steps[j];
    for (int i = 1; i <= n; i++){
        if (i < step) continue; // 台阶少于跨越的步数
         dp[i] += dp[i - step];
    }
}
```
嵌套循环是否能够调换，调换之后的 `dp` 方程的含义有没有改变？

### 6.4.3 和硬币交换II的比较

在硬币交换II题目中，它的一维 `dp` 循环是下面这样：
```java
for (int j = 1; j <= coins.length; j++) {
    int coin = coins[i - 1];
    for (int i = 1; i <= amount; i++) {
        if (i < coin) continue;
        dp[i] += dp[i - coin];
    }
}
```
我们惊奇的发现，它竟然就是上面交换了内外循环的爬楼梯代码！

先不考虑上面的循环（也就是硬币交换II的原解）。我们尝试定义它的子问题：`problem(i) = sum(problem(i-j)), j=1,2,5,...`。
含义为凑成总金额 `i` 的硬币组合数等于凑成总金额硬币 `i-1, i-2, i-5,...` 的子问题之和。

利用这个子问题的定义，我们可以写出下面的代码：
```java
for (int i = 1; i <= amount; i++){
    for (int j = 0; j < coins.length; j++){
        int coin = coins[j - 1];
        if (j < coin) continue;
        dp[i] += dp[i - coin];
    }
}
```
我们发现，这个子问题定义下的循环嵌套顺序和爬楼梯是一样的，和我们之前的硬币交换II题解是相反的。
如果试着运行，却发现这个代码并不正确，得到的结果比预期的大。这是为什么呢？为什么交换了循环结果就不一样了呢？

**我们再来看一下这个子问题定义：`problem(i) = sum(problem(i-j))`，注意到它要求最后一个硬币必须是 `j`**。
这个定义导致了 `...,j,other` 和 `...,other,j` 是两种不同的情况。也就是说，该代码计算的结果是**排列数**，而不是**组合数**。
它是先变化总金额，再变化硬币。最根本的原因是**我们子问题定义出现了错误**。

对于硬币数放在外边，金额数放在里面的情况，它的子问题定义就被改变了。此时的子问题是：对于硬币从 0 到 `j`，
我们必须使用第 `j` 个硬币的时候，当前金额的组合数。因此此时状态数组 `dp[i]` 表示的是对于前 `j` 个硬币凑出金额 `i` 的组合数。

可以这样理解：如果硬币数放在外层，金额数放里层相当于规定了先使用小的硬币，再使用大的硬币，硬币使用的顺序是规定好的，
因此求的是组合数；金额数放外层则是可以改变使用硬币的顺序，而所凑的金额数的顺序是规定好的，因此求的是排列数。
一个必须顺序选择第 `j` 个硬币时，凑成金额 `i` 的方案；一个是对于金额 `i`, 我们选择硬币的方案。

### 6.4.4 二维和一维的不同

对于求硬币的组合数，正确的子问题定义应该是，`problem(j,i) = problem(j-1, i) + problem(j, i-j)`。
即前 `j` 个硬币凑齐金额 `i` 的组合数等于前 `j-1` 个硬币凑齐金额 `i` 的组合数加上在原来 `i-j` 的基础上使用硬币的组合数。
说的更加直白一点，那就是用前 `j` 的硬币凑齐金额 `i`。要分为两种情况考虑：一种是没有用 `coins[j-1]`，前 `j-1` 个硬币就凑齐了；
一种是前面已经凑到了 `i-coins[j-1]`，现在就差第 `j` 个硬币了。

这和我们二维 `dp` 数组的 `dp[i][j] = dp[i-1][j] + dp[i][j-coins[i-1]]` 形式是一致的。

如果你把硬币交换II的二维 `dp` 数组解法的内外循环交换，会发现和一维不同的是，结果还是正确的！
```java
public int change(int amount, int[] coins) {
    if (amount == 0)
        return 1;

    final int n = coins.length;
    final int[][] dp = new int[n + 1][amount + 1];
    for (int i = 0; i <= n; i++)
        dp[i][0] = 1;

    for (int j = 1; j <= amount; j++) {
        for (int i = 1; i <= n; i++) {
            dp[i][j] = dp[i - 1][j];
            if (coins[i - 1] <= j)
                dp[i][j] += dp[i][j - coins[i - 1]];
        }
    }

    // 结果正确
    return dp[n][amount];
}
```
因为这是个组合问题，我们不关心硬币使用的顺序，而是硬币有没有被用到。是否使用第 `k` 个硬币受到之前情况的影响。

这里交换了内外循环后，数组的扫描顺序从行扫描（从左到右，再从上到下）变成了列扫描（从上到下，再从左到右）。
因为 `dp[i][j]` 依赖于 `dp[i - 1][j]` 和 `dp[i][j - coins[i - 1]]`，也就是上面和左边的状态，所以行扫描和列扫描都没问题。
**状态转移没有发生改变，因此子问题的定义（同上面的 `problem(k,i)`）并没有变**，所以不会影响最终的结果。

### 6.4.5 小结

可以看到，子问题定义的不同，会导致运算法则和结果差别很大。而且我们注意到，状态压缩后的 `dp` 数组和未压缩的 `dp` 数组之间的定义已经不一样了。
但只要遵循状态压缩的基本准则，也就不会导致两者的结果出现差异。

最后，我们回答之前爬楼梯的留下的问题。如果跨越的步数放在外层，台阶数放里层相当于规定了先爬小的台阶数，
再爬大的台阶数，求的是组合数；台阶数放外层则是可以改变跨越步数的顺序，三阶可以是先爬一阶再爬两阶，
也可以是先爬两阶再爬一阶，求的是排列数。

# 7. 博弈问题

本文就借石头游戏来讲讲「假设两个人都足够聪明，最后谁会获胜」这一类问题该如何用动态规划算法解决。

博弈类问题的套路都差不多，下文举例讲解，其核心思路是在二维 `dp` 的基础上使用元组分别存储两个人的博弈结果。
掌握了这个技巧以后，别人再问你什么俩海盗分宝石，俩人拿硬币的问题，你就告诉别人：我懒得想，直接给你写个算法算一下得了。

## 7.1 热身：石子问题——画出状态树

我们先来看一个简单的题目：

![石子问题][gt-stone]

其实这个问题可以不用动态规划算法，[使用数学解法只需要一行就可以求得结果][stone]。但这里我们使用它来说明博弈问题如何用动规解决。

题目中很关键的信息或条件：
 - 每一次的选择：每次只能取一堆石子，或者在开始处，或者在结尾处；
 - 游戏终止条件：最后一堆石子被取走；
 - 获胜条件：哪一个玩家获得的石子总数最多。

我们可以通过画图进行分析，其中下图中的 ①②③④ 在后面会说明。其中：
 - 绿色框表示当前 Alex 做出选择；
 - 蓝色框表示当前 Lee 做出选择。

我们采用这样一种计算的方式，**当前自己做出选择的时候，得分为正，留给对方做选择的时候，相对于自己而言，得分为负**。
也就是定义的都是「相对分数」，这种定义是可以推广开来的。动态规划在状态转移的过程中，每一步考虑「相对分数」最大，
即综合了「正分」和「负分」的结果得出最佳选择。

![状态选择树][gt-stone-tree]

1. ① 先从只有 2 堆石子的时候开始考虑，当前做出选择的人，一定会选一个较大的，好让对方拿较少的。
2. ② 再考虑这里，Lee 不管是选择 5 还是 3 ，在下一轮 Alex 按照最优选择，都会让自己比 Lee 多 1，为了让 Lee 总分更多，
Lee 会选 5。此时 Lee 得到的相对分数就是 4。
3. ③ 再考虑这里，Lee 可以选择 5 或者 4：
    - Lee 选择 5 的时候，下一轮 Alex 会让自己多 1 分，因此选择 5 的时候，Lee 的相对分数是 5 - 1 = 4，
    - Lee 选择 4 的时候，下一轮 Alex 会让自己多 2 分，因此选择 4 的时候，Lee 的相对分数是 4 - 2 = 2，
    Lee 为了得到最多的分数，会选择 5。
4. 再考虑这里，Alex 可以选择左边 5 或者右边 5
    - Alex 选择左边 5 的时候，下一轮 Alex 会让自己多 4 分，因此选择左边 5 的时候，Alex 的相对分数是 5 - 4 = 1，
    - Alex 选择右边 5 的时候，下一轮 Alex 会让自己多 4 分，因此选择右边 5 的时候，Alex 的相对分数是 5 - 4 = 1。
    所以 Alex 一定会赢。

结果分析，最后我们可以写出以下代码：
```java
public boolean dpMethod(int[] piles) {
    final int n = piles.length;
    /*
    dp[i][j] 表示在 piles[i..j] 范围内，先手和后手的分数之差。
    当范围内元素数量为偶数时，表示是亚历克斯先选，否则是李先选（因为亚历克斯先手，且牌堆数初始为偶数）
    也就是说当前自己做出选择的时候，得分为正，留给对方做选择的时候，相对于自己而言，得分为负。
    状态转移：dp[i][j] = max(piles[i] - dp[i+1][j], piles[j] - dp[i][j-1])
    通过这种方式，就能够表达两者分别所做的最优选择。
    */
    final int[][] dp = new int[n][n];
    // base case
    for (int i = 0; i < n; i++) {
        dp[i][i] = piles[i];
    }
    // i > j 的都是无效的

    // 当前状态依赖左边和下方的状态，因此从下到上、从左到右进行扫描
    for (int i = n - 2; i >= 0; i--) {
        for (int j = i + 1; j < n; j++) {
            dp[i][j] = Math.max(piles[i] - dp[i + 1][j], piles[j] - dp[i][j - 1]);
        }
    }

    return dp[0][n-1] > 0;
}
```

## 7.2 进阶：石子问题扩展

我们「石头游戏」改的更具有一般性：你和你的朋友面前有一排石头堆，用一个数组 `piles` 表示，
`piles[i]` 表示第 `i` 堆石子有多少个。你们轮流拿石头，一次拿一堆，但是只能拿走最左边或者最右边的石头堆。
所有石头被拿完后，谁拥有的石头多，谁获胜。

石头的堆数可以是任意正整数，石头的总数也可以是任意正整数，这样就能打破先手必胜的局面了。比如有三堆石头 `piles = [1,100,3]`，
先手不管拿 1 还是 3，能够决定胜负的 100 都会被后手拿走，后手会获胜。

**假设两人都很聪明**，请你设计一个算法，返回先手和后手的最后得分（石头总数）之差。比如上面那个例子，先手能获得 4 分，
后手会获得 100 分，你的算法应该返回 -96。

博弈问题的难点在于，两个人要轮流进行选择，而且都贼精明，应该如何编程表示这个过程呢？

### 7.2.1 定义 dp 数组的含义

定义 `dp` 数组的含义是很有技术含量的，同一问题可能有多种定义方法，不同的定义会引出不同的状态转移方程，不过只要逻辑没有问题，
最终都能得到相同的答案。

介绍 `dp` 数组的含义之前，我们先看一下 `dp` 数组最终的样子：

![dp 数组][gt-stone2]

下文讲解时，认为元组是包含 `first` 和 `second` 属性的一个类，而且为了节省篇幅，将这两个属性简写为 `fir` 和 `sec`。
比如按上图的数据，我们说 `dp[1][3].fir = 10`，`dp[0][1].sec = 3`。以下是对 `dp` 数组含义的解释：

![dp 数组含义][gt-stone2-table]

我们想求的答案是先手和后手最终分数之差，按照这个定义也就是 `dp[0][n−1].fir − dp[0][n−1].sec`。

### 7.2.2 状态转移方程

写状态转移方程很简单，首先要找到所有「状态」和每个状态可以做的「选择」，然后择优。
根据前面对 `dp` 数组的定义，状态显然有三个：开始的索引 `i`，结束的索引 `j`，当前轮到的人。
```
dp[i][j][fir or sec]
其中：
0 <= i < piles.length
i <= j < piles.length
```

对于这个问题的每个状态，可以做的选择有两个：选择最左边的那堆石头，或者选择最右边的那堆石头。我们可以这样穷举所有状态：
```python
n = piles.length
for 0 <= i < n:
    for i <= j < n:
        for who in {fir, sec}:
            dp[i][j][who] = max(left, right)
```

上面的伪码是动态规划的一个大致的框架。这道题的难点在于，两人是交替进行选择的，也就是说先手的选择会对后手有影响，
这怎么表达出来呢？根据我们对 `dp` 数组的定义，很容易解决这个难点，写出状态转移方程：

![状态转移方程][gt-stone2-func]

根据 `dp` 数组的定义，我们也可以找出 base case，也就是最简单的情况：

![base case][gt-stone2-base]

### 7.2.3 代码实现

直接把我们的状态转移方程翻译成代码即可，可以注意一下斜着遍历数组的技巧：
```java
class Pair {
    int fir, sec;
    Pair(int fir, int sec) {
        this.fir = fir;
        this.sec = sec;
    }
}

int stoneGame(int[] piles) {
    final int n = piles.length;
    final Pair[][] dp = new Pair[n][n];
    for (int i = 0; i < n; i++) {
        for (int j = 0; j < n; j++) {
            dp[i][j] = new Pair(0, 0);
        }
    }
    for (int i = 0; i < n; i++)
        dp[i][i].fir = piles[i];

    // 斜着遍历
    for (int l = 2; l <= n; l++) {
        for (int i = 0; i <= n - l; i++) {
            int j = l + i - 1;
            int left = piles[i] + dp[i + 1][j].sec;
            int right = piles[j] + dp[i][j - 1].sec;
            if (left > right) {
                dp[i][j].fir = left;
                dp[i][j].sec = dp[i + 1][j].fir;
            } else {
                dp[i][j].fir = right;
                dp[i][j].sec = dp[i][j - 1].fir;
            }
        }
    }

    Pair res = dp[0][n - 1];
    return res.fir - res.sec;
}
```

注意到计算 `dp[i][j]` 只依赖其左边和下边的元素，所以说肯定有优化空间，转换成一维 `dp`，想象一下把二维平面压扁，也就是投影到一维。
但是，一维 `dp` 比较复杂，可解释性很差，大家就不必浪费这个时间去理解了。

### 7.2.4 总结

本文给出了解决博弈问题的动态规划解法。博弈问题的前提一般都是在两个聪明人之间进行，编程描述这种游戏的一般方法是二维 `dp` 数组，
数组中通过元组分别表示两人的最优决策。

之所以这样设计，是因为先手在做出选择之后，就成了后手，后手在对方做完选择后，就变成了先手。
**这种角色转换使得我们可以重用之前的结果**，典型的动态规划标志。

# 8. 股票问题

LeetCode 上有 6 道关于股票买卖的问题，难度较大。本文给大家分析出一套框架，只要通过简单的变形，就能解决所有问题。

## 8.1 说明

首先申明，开始的动态规划方法的只是一个种可行方案，不是最优的。这几道股票买卖题目测试数据的规模非常大，
所以有几道题目按照开始的动态规划方法进行提交是无法通过的，会在最后一个测试用例得到超时或超内存的错误。

虽然不能通过，我还是写了这篇文章，说明一下用意：学习的过程分为两个阶段，先是「从 0 到 1」，然后「从 1 到 N」。
你看懂一道题，只能算「从 0 到 1」，如果不能复现这种设计思路解决一类问题，那么过两天你就忘了。但是如果你能掌握一个框架，
就能无限复制，举一反三，解决一大类问题。显然后者的价值更大。

本文给出的动态规划思路复杂度是 O(N^2)，经过简单变形就能处理所有问题，层层递进，可读性好。最优解法复杂度 O(N)，涉及状态机，比较难以理解。

## 8.2 例 1：买卖股票的最佳时机——穷举，然后尝试消除循环

![买卖股票的最佳时机][stock-1]

遇到一个问题，如果想不到什么奇技淫巧，那么首先请读者自问：**如何穷举这个问题的所有可能性**？

这个问题的穷举很简单，我们可以这样写：
```java
public int maxProfit(int[] prices) {
    int res = 0;
    for (int buy = 0; buy < prices.length - 1; buy++) {
        for (int sell = buy + 1; sell < prices.length; sell++)
            res = Math.max(res, prices[sell] - prices[buy]);
    }
    return res;
}
```

实际上，这个解法就是可行的，能够得到正确答案。但是我们分析一下这个算法在干嘛，就能发现一些冗余计算。

![冗余计算][stock-1-map]

如上图，可以看到大量的重复操作。我们相当于固定了买入时间 `buy`，然后将 `buy` 后面的每一天作为 `sell` 进行穷举，
只为寻找 `prices[sell]` 最大的那天，因为这样 `prices[sell] - prices[buy]` 的差价才会最大。

如果反过来想，固定卖出时间 `sell`，向前穷举买入时间 `buy`，寻找 `prices[buy]` 最小的那天，是不是也能达到相同的效果？
是的，而且这种思路可以减少一个 `for` 循环：
```java
public int maxProfit(int[] prices) {
    int res = 0;
    int curMin = prices[0];
    for (int sell = 1; sell < prices.length; sell++) {
        curMin = Math.min(curMin, prices[sell]);
        res = Math.max(res, prices[sell] - curMin);
    }

    return res;
}
```

为什么可以减少一个 `for` 循环呢？我举个例子你就很容易理解了。

假设你有一堆数字，你知道其中最大的数，现在从中取走一个数，你还知道最大的那个数是多少吗？不一定，
如果拿走的这个数不是那个最大数，那么最大数不变；如果拿走的恰好是那个最大的数，你就得重新遍历这堆数字以寻找之前第二大的那个数，
作为新的最大数。这就是我们的原始算法，每向后移动一位，就要重新遍历寻找最大值。

但是，假设你知道一堆数字中最小的那个，再添加一个新的数字，你现在是否知道最小的数字是那个？知道，只要比较一下新数和当前最小的数字，
就能得到新的最小数。这就是优化算法的情况，所以可以消除嵌套循环的计算冗余。

关键不在于最大值还是最小值，而是**数字的添加和减少能否推导出新的最值**。添加新数时，可以根据已有最值，推导出新的最值；而减少数字时，
不一定能直接推出新的最值，不得不重新遍历。

很多人认为这道题不是动态规划，但是我认为最值的更新就是旧状态向新状态的转移，所以这个问题还是含有动态规划的技巧的。
**不要觉得此题简单，这里完成了最困难的一步：穷举。后面所有的题目都可以基于此框架扩展出来**。

## 8.3 例 2：买卖股票的最佳时机 II

![题目][stock-2]

这道题允许多次交易，看起来比刚才的问题复杂了很多，怎么办？没有思路第一步，想想如何穷举所有可能结果。来尝试一下吧，
如果用 `for` 循环来穷举，会出现什么情况？
```java
for (int buy = 0; buy < prices.length - 1; buy++) {
    for (int sell = buy + 1; sell < prices.length; sell++) {
        if (prices[sell] > prices[buy]) { for for ...}
        else { for for ...}
    }
}
```

**遇到这种无穷 `for` 循环的情况，就是使用递归的强烈暗示**。我们上一题的框架只能解决一次买卖的最大收益，
现在的问题是，进行一次股票卖出后，下一次应该在什么时候交易呢？这个问题和原问题具有相同结构，规模减小，典型的递归场景。
只要给原框架稍加改动即可：
```java
int maxProfit(int[] prices, int lo, int hi) {
    int res = 0;
    for (int buy = lo; buy <= hi - 1; buy++) {
        for (int sell = buy + 1; sell <= hi; sell++) {
            if (prices[sell] > prices[buy])
                res = Math.max(res, prices[sell] - prices[buy] + recur(prices, sell + 1, hi));
            else
                res = Math.max(res, recur(prices, sell + 1, hi));
        }
    }

    return res;
}
```

这道题已经做出来了，**优化两步：先根据上一题消除一层循环，然后加个备忘录**。优化就属于走流程，没啥可说的。
之后问题的解法，都是在此代码上的简单改造：
```java
public int maxProfit(int[] prices) {
    return maxProfit(prices, 0, new HashMap<>((int) (prices.length / 0.75)));
}

private int maxProfit(int[] prices, int lo, Map<Integer, Integer> memory) {
    if (lo >= prices.length - 1)
        return 0;
    int res = memory.getOrDefault(lo, -1);
    if (res != -1)
        return res;

    int curMin = prices[lo];
    for (int sell = lo + 1; sell <= prices.length - 1; sell++) {
        curMin = Math.min(curMin, prices[sell]);
        res = Math.max(res, prices[sell] - curMin + maxProfit(prices, sell + 1, memory));
    }
    memory.put(lo, res);

    return res;
}
```

但是，这样提交会得到一个内存超过限制的错误。原来有一个测试用例特别长，我们的 `memory` 备忘录太大了。怎么办呢，
是否可以想办法减小备忘录占用的空间？答案是不可以。我们抽象出当前算法的框架：
```java
def dp(start):
    for sell in range(start + 1, len(prices)):
        dp(sell)
```

显然，如果求解原问题 `dp(0)`，要依赖子问题 `dp(1), dp(2) ... dp(len(prices) - 1)`，反正数量不是个定值，
所以备忘录必须开那么大，否则装不下这些依赖子问题呀！说明这就是动态规划的极限了，真的不能再优化了。

这个问题的最优解法是「贪心算法」。贪心算法是基于动态规划之上的一种特殊方法，对于某些特定问题可以比动态规划更高效。
这道题用贪心算法的核心思想就是：既然可以预知未来，那么能赚一点就赚一点：
```java
public int maxProfit(int[] prices) {
    int maxProfit = 0;
    for (int i = 1; i < prices.length; i++) {
        if (prices[i] > prices[i - 1])
            maxProfit += prices[i] - prices[i - 1];
    }

    return maxProfit;
}
```

## 8.4 例 3：买卖股票的最佳时机 III/IV

第三题和第四题类似，就是限定了你的最大交易次数，只要解决第四题就行了，看题目：

![题目][stock-4]

直接套上面的框架，把这个约束 `k` 加进去即可：
```java
public int maxProfit(int k, int[] prices) {
    return maxProfit(prices, 0, k, new HashMap<>((int) (prices.length / 0.75) * 2));
}

// 加上约束 k
public int maxProfit(int[] prices, int lo, int k, Map<Pair<Integer, Integer>, Integer> memory) {
    if (lo >= prices.length - 1 || k == 0)
        return 0;
    Pair<Integer, Integer> cur = new Pair<>(lo, k);
    int res = memory.getOrDefault(cur, -1);
    if (res != -1)
        return res;

    int curMin = prices[lo];
    for (int sell = lo + 1; sell < prices.length; sell++) {
        curMin = Math.min(curMin, prices[sell]);
        res = Math.max(res, prices[sell] - curMin + maxProfit(prices, sell + 1, k - 1, memory));
    }
    memory.put(cur, res);

    return res;
}
```

时间复杂度 O(kN^2)，会在最后一个测试用例超时，不过好歹做出来一个可行答案，起码有 90 分吧。

## 8.5 例 4：最佳买卖股票时机含冷冻期

![冷冻期][stock-cooldown]

没啥好说的，套框架：
```java
public int maxProfit(int[] prices) {
    return maxProfit(prices, 0, new HashMap<>((int) (prices.length / 0.75)));
}

private int maxProfit(int[] prices, int lo, Map<Integer, Integer> memory) {
    if (lo >= prices.length - 1)
        return 0;
    int res = memory.getOrDefault(lo, -1);
    if (res != -1)
        return res;

    int curMin = prices[lo];
    for (int sell = lo + 1; sell < prices.length; sell++) {
        curMin = Math.min(curMin, prices[sell]);
        // sell + 2，冷静一天
        res = Math.max(res, prices[sell] - curMin + maxProfit(prices, sell + 2, memory));
    }
    memory.put(lo, res);

    return res;
}
```
此解法通过了全部的测试样例，只是有些低效。

## 8.6 例 5：买卖股票的最佳时机含手续费

![题目][stock-fee]

每次卖出需要手续费，套进框架，把手续费从利润中减掉即可：
```java
public int maxProfit(int[] prices, int fee) {
    return maxProfit(prices, fee, 0, new HashMap<>((int) (prices.length / 0.75)));
}

private int maxProfit(int[] prices, int fee, int lo, Map<Integer, Integer> memory) {
    if (lo >= prices.length - 1)
        return 0;
    int res = memory.getOrDefault(lo, -1);
    if (res != -1)
        return res;
    // 注意置 0，因为减去手续费后费用可能为负
    res = 0;

    int curMin = prices[lo];
    for (int sell = lo + 1; sell < prices.length; sell++) {
        curMin = Math.min(curMin, prices[sell]);
        // 减去手续费
        res = Math.max(res, prices[sell] - curMin - fee + maxProfit(prices, fee, sell + 1, memory));
    }
    memory.put(lo, res);

    return res;
}
```
最后一个测试用例超出时间限制。

总结一下，我们通过最简单的两个问题，形成了一套算法模板，快速解决了剩下的困难问题。通过备忘录技巧，
保持时间复杂度在 O(N^2) 级别，虽不是最优的，但也是可行的。

## 8.7 使用状态机改进算法

之前我们用动态规划和递归的方法实现了一套简单易懂的可行解，但是时间复杂度略高，不能通过全部测试用例。
这篇文章用「状态机」的技巧给出最优解，可以全部提交通过。

这 6 道题目是有共性的，本文通过对第四道题（买卖股票的最佳时机 IV）的分析，逐步解决所有问题。因为第四题是一个最泛化的形式，
其他的问题都是这个形式的简化。

### 8.7.1 穷举框架

这里，我们不用递归思想进行穷举，而是利用「状态」进行穷举。看看总共有几种「状态」，再找出每个「状态」对应的「选择」。
我们要穷举所有「状态」，穷举的目的是根据对应的「选择」更新状态。看图，就是这个意思：

![状态穷举][stock-state-machine]

具体到当前问题，**每天都有三种「选择」：买入、卖出、无操作**，我们用 `buy, sell, rest` 表示这三种选择。

但问题是，并不是每天都可以任意选择这三种选择的，因为 `sell` 必须在 `buy` 之后，`buy` 必须在 `sell` 之后（第一次除外）。
那么 `rest` 操作还应该分两种状态，一种是 `buy` 之后的 `rest`（持有了股票），一种是 `sell` 之后的 `rest`（没有持有股票）。
而且别忘了，我们还有交易次数 `k` 的限制，就是说你 `buy` 还只能在 `k > 0` 的前提下操作。

很复杂对吧，不要怕，我们现在的目的只是穷举，你有再多的状态，老夫要做的就是一把梭全部列举出来。**这个问题的「状态」有三个**，
第一个是天数，第二个是当天允许交易的最大次数，第三个是当前的持有状态（即之前说的 rest 的状态，我们不妨用 1 表示持有，
0 表示没有持有）。

我们用一个三维数组 `dp` 就可以装下这几种状态的全部组合，用 `for` 循环就能完成穷举：

![穷举][stock-state-machine-for]

而且我们可以用自然语言描述出每一个状态的含义，比如说 `dp[3][2][1]` 的含义就是：今天是第三天，我现在手上持有着股票，
至今最多进行 2 次交易。再比如 `dp[2][3][0]` 的含义：今天是第二天，我现在手上没有持有股票，至今最多进行 3 次交易。
很容易理解，对吧？

我们想求的最终答案是 `dp[n - 1][K][0]`，即最后一天，最多允许 `K` 次交易，所能获取的最大利润。
读者可能问为什么不是 `dp[n - 1][K][1]`？因为 `[1]` 代表手上还持有股票，`[0]` 表示手上的股票已经卖出去了，
很显然后者得到的利润一定大于前者。

记住如何解释「状态」，一旦你觉得哪里不好理解，把它翻译成自然语言就容易理解了。

### 8.7.2 状态转移框架

现在，我们完成了「状态」的穷举，我们开始思考每种「状态」有哪些「选择」，应该如何更新「状态」。

因为我们的选择是 `buy, sell, rest`，而这些选择是和「持有状态」相关的，所以只看「持有状态」，可以画个状态转移图。

![状态转移图][stock-state-machine-transfer]

通过这个图可以很清楚地看到，每种状态（0 和 1）是如何转移而来的。根据这个图，我们来写一下状态转移方程：

![状态转移方程][stock-state-machine-func]

这个解释应该很清楚了，如果 `buy`，就要从利润中减去 `prices[i]`，如果 `sell`，就要给利润增加 `prices[i]`。
今天的最大利润就是这两种可能选择中较大的那个。而且注意 `k` 的限制，我们在选择 `buy` 的时候，把最大交易数 `k` 减小了 1，
很好理解吧，当然你也可以在 `sell` 的时候减 1，一样的。

现在，我们已经完成了动态规划中最困难的一步：状态转移方程。如果之前的内容你都可以理解，那么你已经可以秒杀所有问题了，
只要套这个框架就行了。不过还差最后一点点，就是定义 base case，即最简单的情况。

![base case][stock-state-machine-base]

### 8.7.3 编码和状态压缩

经过上面的分析，写出代码也就是信手拈来了：
```java
public int maxProfit(int k, int[] prices) {
    final int days = prices.length;
    // 三个状态：天数、当天允许交易的最大次数、当前的持有状态。存的是最大利润
    final int[][][] dp = new int[days + 1][k + 1][2];

    // base case
    for (int i = 0; i <= k; i++) {
        dp[0][i][1] = Integer.MIN_VALUE;
    }
    for (int i = 0; i <= days; i++) {
        dp[i][0][1] = Integer.MIN_VALUE;
    }

    for (int i = 1; i <= days; i++) {
        for (int j = 1; j <= k; j++) {
            // 从（昨天没有持有，今天不操作，还是没有持有）和（昨天持有，今天卖出了，所以今天没有持有了）中选择最大的
            dp[i][j][0] = Math.max(dp[i - 1][j][0], dp[i - 1][j][1] + prices[i - 1]);
            // 从（昨天持有，今天不操作，继续持有）和（昨天没有持有，今天买了，所以今天持有了）中选择最大的
            dp[i][j][1] = Math.max(dp[i - 1][j][1], dp[i - 1][j - 1][0] - prices[i - 1]);
        }
    }

    return dp[days][k][0];
}
```

可以看到，当前状态只用到了上边和左上两个状态，因此可以进行状态压缩：
```java
public int maxProfit(int k, int[] prices) {
    final int days = prices.length;
    // 压缩行
    final int[][] dp = new int[k + 1][2];
    for (int i = 0; i <= k; i++) {
        dp[i][1] = Integer.MIN_VALUE;
    }

    for (int i = 1; i <= days; i++) {
        // 注意从右到左，因为后一状态依赖前面的状态
        for (int j = k; j >= 1; j--) {
            dp[j][0] = Math.max(dp[j][0], dp[j][1] + prices[i - 1]);
            dp[j][1] = Math.max(dp[j][1], dp[j - 1][0] - prices[i - 1]);
        }
    }

    return dp[k][0];
}
```

### 8.7.4 解决其他题目

#### 8.7.4.1 买卖股票的最佳时机

```java
public int maxProfit(int[] prices) {
    final int days = prices.length;
    int noHold = 0, hold = Integer.MIN_VALUE;

    for (int i = 0; i < days; i++) {
        noHold = Math.max(noHold, hold + prices[i]);
        // 注意，k == 1，所以已经不需要任何 k 了，或者说 dp[j-1][0] 恒等于 0，因此这里直接就是 -prices[i]
        hold = Math.max(hold, -prices[i]);
    }

    return noHold;
}
```

#### 8.7.4.2 买卖股票的最佳时机 II

```java
public int maxProfit(int[] prices) {
    final int days = prices.length;
    int noHold = 0, hold = Integer.MIN_VALUE;

    for (int i = 0; i < days; i++) {
        // k 无穷，则 k 和 k - 1 是一样的。
        // 注意先保存 noHold，防止值被改变
        int tmp = noHold;
        noHold = Math.max(noHold, hold + prices[i]);
        hold = Math.max(hold, tmp - prices[i]);
    }

    return noHold;
}
```

#### 8.7.4.3 买卖股票的最佳时机 III

```java
public int maxProfit(int[] prices) {
    final int days = prices.length;
    // 压缩行
    final int[][] dp = new int[2 + 1][2];
    for (int i = 0; i <= 2; i++) {
        dp[i][1] = Integer.MIN_VALUE;
    }

    for (int i = 1; i <= days; i++) {
        // 注意从右到左，因为后一状态依赖前面的状态
        for (int j = 2; j >= 1; j--) {
            dp[j][0] = Math.max(dp[j][0], dp[j][1] + prices[i - 1]);
            dp[j][1] = Math.max(dp[j][1], dp[j - 1][0] - prices[i - 1]);
        }
    }

    return dp[2][0];
}
```

#### 8.7.4.4 最佳买卖股票时机含冷冻期

```java
public int maxProfit(int[] prices) {
    final int days = prices.length;
    // 使用 lastNoHold 表示上上次没有持有的状态
    int noHold = 0, hold = Integer.MIN_VALUE, lastNoHold = 0;
    for (int i = 0; i < days; i++) {
        // k 无穷，则 k 和 k - 1 是一样的。
        // 注意先保存 noHold，防止值被改变
        int tmp = noHold;
        noHold = Math.max(noHold, hold + prices[i]);
        // 等一天：dp[i][1] = max(dp[i-1][1], dp[i-2][0] - prices[i])
        // 第 i 天选择买入时，要从 i - 2 的状态转移（因为只有卖出才能买入，而卖出后需要等一天）
        hold = Math.max(hold, lastNoHold - prices[i]);
        lastNoHold = tmp;
    }

    return noHold;
}
```

#### 8.7.4.5 买卖股票的最佳时机含手续费

```java
public int maxProfit(int[] prices, int fee) {
    final int days = prices.length;
    int noHold = 0, hold = Integer.MIN_VALUE;

    for (int i = 0; i < days; i++) {
        // k 无穷，则 k 和 k - 1 是一样的。
        // 注意先保存 noHold，防止值被改变
        int tmp = noHold;
        noHold = Math.max(noHold, hold + prices[i]);
        // 买入减去手续费。之所以在这里减，是因为 hold 可能为 MIN_VALUE 导致负溢出
        hold = Math.max(hold, tmp - prices[i] - fee);
    }

    return noHold;
}
```


[bs]: ../binarysearch/README.md

[coin-java]: E322_Medium_CoinChange.java
[stone]: ../gametheory/E877_Medium_StoneGame.java

[fib]: ../../../res/img/dp-fib.jpg
[fib-reduce]: ../../../res/img/dp-fib-reduce.jpg
[fib-graph]: ../../../res/img/dp-fib-graph.jpg
[fib-table]: ../../../res/img/dp-fib-table.jpg
[fib-function]: ../../../res/img/dp-fib-function.png
[coin-function]: ../../../res/img/dp-coin-function.png
[coin-tree]: ../../../res/img/dp-coin-tree.jpg
[four-title]: ../../../res/img/dp-four-title.jpg
[four-procedure]: ../../../res/img/dp-four-procedure.jpg
[egg-function]: ../../../res/img/dp-egg-function.jpg
[egg-func-graph]: ../../../res/img/dp-egg-func-graph.jpg
[lcs]: ../../../res/img/dp-lcs.png
[lcs-table]: ../../../res/img/dp-lcs-table.jpg
[lcs-sub]: ../../../res/img/dp-lcs-sub.jpg
[edit-distance]: ../../../res/img/dp-edit-distance.jpg
[edit-distance-procedure]: ../../../res/img/dp-edit-distance-procedure.gif
[edit-distance-static]: ../../../res/img/dp-edit-distance-static.jpg
[edit-distance-table]: ../../../res/img/dp-edit-distance-table.jpg
[edit-distance-choice]: ../../../res/img/dp-edit-distance-choice.jpg
[edit-distance-path]: ../../../res/img/dp-edit-distance-path.jpg
[lis-question]: ../../../res/img/dp-lis-question.png
[lis-procedure]: ../../../res/img/dp-lis-procedure.gif
[lis-induction]: ../../../res/img/dp-lis-induction.jpg
[lis-bs]: ../../../res/img/dp-lis-bs.jpg
[lis-poker]: ../../../res/img/dp-lis-poker.jpg
[lis-result]: ../../../res/img/dp-lis-result.jpg
[nest-question]: ../../../res/img/dp-nest-question.PNG
[nest-sort]: ../../../res/img/dp-nest-sort.jpg
[nest-lis]: ../../../res/img/dp-nest-lis.jpg
[lps-question]: ../../../res/img/dp-lps-question.png
[lps-eq]: ../../../res/img/dp-lps-eq.jpg
[lps-ne]: ../../../res/img/dp-lps-ne.jpg
[lps-table]: ../../../res/img/dp-lps-table.jpg
[lps-scan]: ../../../res/img/dp-lps-scan.jpg
[lps-state]: ../../../res/img/dp-lps-state.jpg
[lps-projection]: ../../../res/img/dp-lps-projection.jpg
[lps-base]: ../../../res/img/dp-lps-base.jpg
[scan-edit]: ../../../res/img/dp-scan-edit.jpg
[bag-subset]: ../../../res/img/dp-bag-subset.PNG
[bag-coin]: ../../../res/img/dp-bag-coin.PNG
[bag-coin-e1]: ../../../res/img/dp-bag-coin-e1.png
[bag-coin-e2]: ../../../res/img/dp-bag-coin-e2.png
[bag-coin-e3]: ../../../res/img/dp-bag-coin-e3.png
[bag-coin-e4]: ../../../res/img/dp-bag-coin-e4.PNG
[bag-stair]: ../../../res/img/dp-bag-stair.PNG
[gt-stone]: ../../../res/img/dp-gt-stone.PNG
[gt-stone-tree]: ../../../res/img/dp-gt-stone-tree.png
[gt-stone2]: ../../../res/img/dp-gt-stone2.png
[gt-stone2-table]: ../../../res/img/dp-gt-stone2-table.jpg
[gt-stone2-func]: ../../../res/img/dp-gt-stone2-func.jpg
[gt-stone2-base]: ../../../res/img/dp-gt-stone2-base.jpg
[stock-1]: ../../../res/img/dp-stock-1.jpg
[stock-1-map]: ../../../res/img/dp-stock-1-map.jpg
[stock-2]: ../../../res/img/dp-stock-2.jpg
[stock-4]: ../../../res/img/dp-stock-4.jpg
[stock-cooldown]: ../../../res/img/dp-stock-cooldown.jpg
[stock-fee]: ../../../res/img/dp-stock-fee.webp
[stock-state-machine]: ../../../res/img/dp-stock-state-machine.png
[stock-state-machine-for]: ../../../res/img/dp-stock-state-machine-for.jpg
[stock-state-machine-transfer]: ../../../res/img/dp-stock-state-machine-transfer.jpg
[stock-state-machine-func]: ../../../res/img/dp-stock-state-machine-func.jpg
[stock-state-machine-base]: ../../../res/img/dp-stock-state-machine-base.jpg

<b id="f1">\[1\]</b> https://labuladong.gitee.io/algo/动态规划系列/动态规划详解进阶.html [↩](#a1)  